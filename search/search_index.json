{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PyReadStore Readstore Python Client (SDK)","text":"<p>PyReadStore is a Python client (SDK) that lets you easily connect to your ReadStore server and interact with the ReadStore API. By importing the pyreadstore package in Python, you can quickly retrieve data from a ReadStore server.</p> <p>This tool provides streamlined and standardized access to NGS datasets and metadata, helping you run analyses more efficiently and with fewer errors. You can easily scale your pipelines, and if you need to migrate or move NGS data, updating the ReadStore database ensures all your workflows stay up-to-date.</p> <p>Find more information on www.evo-byte.com/readstore</p> <p>For technical questions or problems with the install please contact support@evo-byte.com</p>"},{"location":"changelog/","title":"Changelog","text":"<p>pyreadstore - ReadStore Python SDK</p>"},{"location":"changelog/#132-2025-02-11","title":"[1.3.2] - 2025-02-11","text":"<p>Bugfixes - update - Reset dataset associated project </p>"},{"location":"changelog/#131-2025-02-11","title":"[1.3.1] - 2025-02-11","text":"<p>Bugfixes - update - Reset dataset associated project</p>"},{"location":"changelog/#130-2025-02-10","title":"[1.3.0] - 2025-02-10","text":"<p>Features - Add list_metadata methods for project, datasets and ProData to format metadata as data frame - Add update methods for projects and datasets</p> <p>Updates - Code Formatting</p>"},{"location":"changelog/#120-2024-12-23","title":"[1.2.0] - 2024-12-23","text":"<p>Features - Add method rs_client.create: Create new Dataset  - Add method rs_client.delete: Remove Dataset - Add method rs_client.create_project: Create new Project - Add method rs_client.delete_project: Remove Project</p> <p>Updates - Add new create, update, and delete methods - Add validations for metadata - Improved error messages in case of invalid backend requests </p> <p>Bugfixes - Error parsing allowed FASTQ file extensions from ReadStore config file</p>"},{"location":"changelog/#110-2024-12-01","title":"[1.1.0] - 2024-12-01","text":"<p>Features - Add method upload_pro_data - Add method list_pro_data - Add method get_pro_data - Add method delete_pro_data</p> <p>Updates</p> <ul> <li>upload_fastq: Add fastq_name and read_type arguments to enable definition of FASTQ names and read types</li> </ul>"},{"location":"changelog/#100-2024-10-30","title":"[1.0.0] - 2024-10-30","text":"<p>Initial Version</p>"},{"location":"readme/","title":"Readme","text":""},{"location":"readme/#pyreadstore-sdk","title":"PyReadStore SDK","text":"<p>This README describes PyReadStore, the Python client (SDK) for the ReadStore API. </p> <p>The full ReadStore Basic documentation is available here </p> <p>PyReadStore can be used to access Projects, Datasets, ProData as well as metadata and attachment files in the ReadStore Database from Python code.  The package enables you to automate your bioinformatics pipelines, Python scripts and notebooks.</p> <p>Check the ReadStore Github repository for more information on how to get started with ReadStore and setting up your server.</p> <p>More infos on the ReadStore website</p> <p>Tutorials and Intro Videos: https://www.youtube.com/@evobytedigitalbio</p> <p>Blog posts and How-Tos: https://evo-byte.com/blog/</p> <p>For general questions reach out to info@evo-byte.com or in case of technical problems to support@evo-byte.com</p> <p>Happy analysis :)</p>"},{"location":"readme/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Description</li> <li>Installation</li> <li>ReadStore API</li> <li>Usage<ol> <li>Quickstart</li> <li>Client Config</li> <li>Datasets</li> <li>Project</li> <li>ProData</li> <li>Download</li> <li>Upload FASTQ</li> </ol> </li> <li>Contributing</li> <li>License</li> <li>Credits and Acknowledgments</li> </ul>"},{"location":"readme/#the-lean-solution-for-managing-ngs-and-omics-data","title":"The Lean Solution for Managing NGS and Omics Data","text":"<p>ReadStore is a platform for storing, managing, and integrating omics data. It speeds up analysis and offers a simple way of managing and sharing NGS omics datasets, metadata and processed data (Processed Data). Built-in project and metadata management structures your workflows and a collaborative user interface enhances teamwork \u2014 so you can focus on generating insights.</p> <p>The integrated Webservice (API) enables your to directly retrieve data from ReadStore via the terminal Command-Line-Interface (CLI) or Python / R SDKs.</p> <p>The ReadStore Basic version provides a local webserver with a simple user management. If you need an organization-wide deployment, advanced user and group management or cloud integration please check the ReadStore Advanced versions and reach out to info@evo-byte.com.</p>"},{"location":"readme/#description","title":"Description","text":"<p>PyReadStore is a Python client (SDK) that lets you easily connect to your ReadStore server and interact with the ReadStore API. By importing the pyreadstore package in Python, you can quickly retrieve data from a ReadStore server.</p> <p>This tool provides streamlined and standardized access to NGS datasets and metadata, helping you run analyses more efficiently and with fewer errors. You can easily scale your pipelines, and if you need to migrate or move NGS data, updating the ReadStore database ensures all your workflows stay up-to-date.</p>"},{"location":"readme/#security-and-permissions","title":"Security and Permissions","text":"<p>PLEASE READ AND FOLLOW THESE INSTRUCTIONS CAREFULLY!</p>"},{"location":"readme/#user-accounts-and-token","title":"User Accounts and Token","text":"<p>Using PyReadStore requires an active user account and a token (and a running ReadStore server). </p> <p>You should never enter your user account password when working with PyReadStore.</p> <p>To retrieve your token:</p> <ol> <li>Login to the ReadStore app via your browser</li> <li>Navigate to <code>Settings</code> page and click on <code>Token</code></li> <li>You can regenerate your token anytime (<code>Reset</code>). This will invalidate the previous token</li> </ol> <p>For uploading FASTQ files your user account needs to have <code>Staging Permission</code>. You can check this in the <code>Settings</code> page of your account. If you not have <code>Staging Permission</code>, ask your ReadStore server admin to grant you permission.</p>"},{"location":"readme/#setting-your-credentials","title":"Setting Your Credentials","text":"<p>You need to provide the PyReadStore client with valid ReadStore credentials.</p> <p>There are different options</p> <ol> <li> <p>Load credentials from the ReadStore <code>config</code> file.  The file is generated by the ReadStore CLI, by default in your home directory (<code>~/.readstore/</code>). Make sure to keep read permissions to the file restrictive</p> </li> <li> <p>Directly enter your username and token when instantiating a PyReadStore client within your Python code</p> </li> <li> <p>Set username and token via environment variables (<code>READSTORE_USERNAME</code>, <code>READSTORE_TOKEN</code>). This is useful in container or cloud environments.</p> </li> </ol>"},{"location":"readme/#installation","title":"Installation","text":"<p><code>pip3 install pyreadstore</code></p> <p>You can perform the install in a conda or venv virtual environment to simplify package management.</p> <p>A local install is also possible</p> <p><code>pip3 install --user pyreadstore</code></p> <pre><code>import pyreadstore\n</code></pre>"},{"location":"readme/#readstore-api","title":"ReadStore API","text":"<p>The ReadStore Basic server provides a RESTful API for accessing resources via HTTP requests. This API extends the functionalities of the ReadStore CLI as well as the Python and R SDKs.</p>"},{"location":"readme/#api-endpoint","title":"API Endpoint","text":"<p>By default, the API is accessible at: <code>http://127.0.0.1:8000/api_x_v1/</code></p>"},{"location":"readme/#authentication","title":"Authentication","text":"<p>Users must authenticate using their username and token via the Basic Authentication scheme.</p>"},{"location":"readme/#example-usage","title":"Example Usage","text":"<p>Below is an example demonstrating how to use the ReadStore CLI to retrieve an overview of Projects by sending an HTTP <code>GET</code> request to the <code>project/</code> endpoint. In this example, the username is <code>testuser</code>, and the token is <code>0dM9qSU0Q5PLVgDrZRftzw</code>. You can find your token in the ReadStore settings.</p> <pre><code>curl -X GET -u testuser:0dM9qSU0Q5PLVgDrZRftzw http://localhost:8000/api_x_v1/project/\n</code></pre>"},{"location":"readme/#example-reponse","title":"Example Reponse","text":"<p>A successful HTTP response returns a JSON-formatted string describing the project(s) in the ReadStore database. Example response:</p> <pre><code>[{\n  \"id\": 4,\n  \"name\": \"TestProject99\",\n  \"metadata\": {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n  },\n  \"attachments\": []\n}]\n</code></pre>"},{"location":"readme/#documentation","title":"Documentation","text":"<p>Comprehensive API documentation is available in the ReadStore Basic Docs.</p>"},{"location":"readme/#usage","title":"Usage","text":"<p>Detailed tutorials, videos and explanations are found on YouTube or on the EVOBYTE blog.</p>"},{"location":"readme/#quickstart","title":"Quickstart","text":"<p>Let's access some dataset and project data from the ReadStore database!</p> <p>Make sure a ReadStore server is running and reachable (by default under <code>127.0.0.1:8000</code>). You can enter (<code>http://127.0.0.1:8000/api_v1/</code>) in your browser and should get a response from the API.</p> <p>We assume you ran <code>readstore configure</code> before to create a config file for your user. If not, consult the ReadStore CLI README on how to set this up.</p> <p>We will create a client instance and perform some operations to retrieve data from the ReadStore database. More information on all available methods can be found below.</p> <pre><code>import pyreadstore\n\nrs_client = pyreadstore.Client() # Create an instance of the ReadStore client\n\n# Manage Datasets\n\ndatasets = rs_client.list()      # List all datasets and return pandas dataframe\n\ndatasets_project_1 = rs_client.list(project_id = 1) # List all datasets for project 1\n\ndatasets_id_25 = rs_client.get(dataset_id = 25)     # Get detailed data for dataset 25\n\n# Manage Projects\n\nprojects = rs_client.list_projects()                # List all projects\n\nprojects = rs_client.get_project(project_name = 'MyProject') # Get details for MyProject\n\nfastq_data_id_25 = rs_client.get_fastq(dataset_id = 25)     # Get fastq file data for dataset 25\n\nrs_client.download_attachment(dataset_id = 25,              # Download files attached to dataset 25\n                              attachment_name = 'gene_table.tsv') \n\n# Manage Processed Data\n\nrs_client.upload_pro_data(name = 'sample_1_count_matrix',      # Set name of count matrix\n                            pro_data_file = 'path/to/sample_1_counts.h5',   # Set file path\n                            data_type = 'count_matrix',                     # Set type to 'count_matrix'\n                            dataset_id = 25)                                # Set dataset id for upload\n\npro_data_project_1 = rs_client.list_pro_data(project_id = 1) # Get all ProData entries for Project 1\n\npro_data = rs_client.get_pro_data(name = 'sample_1_count_matrix',   # Set name to sample_1_count_matrix\n                                dataset_id = 25)                    # dataset_id\n\npro_data_id = rs_client.delete_pro_data(name = 'sample_1_count_matrix',\n                                        dataset_id = 25)\n\n# Ingest FASTQ files\n\nrs_client.upload_fastq(fastq = ['path/to_fastq_r1.fq', 'path/to_fastq_r2.fq'], # Upload a FASTQ files\n                        fastq_name = ['sample_rep_1_r1', 'sample_rep_1_r2'],    # Set FASTQ names\n                        read_type = ['R1', 'R2'])                               # Set individual FASTQ read types\n</code></pre>"},{"location":"readme/#configure-the-python-client","title":"Configure the Python Client","text":"<p>The Client is the central object and provides authentication against the ReadStore API. By default, the client will try to read the <code>~/.readstore/config</code> credentials file. You can change the directory if your config file is located in another folder.</p> <p>If you set the <code>username</code> and <code>token</code> arguments, the client will use these credentials instead.</p> <p>If your ReadStore server is not running under localhost (<code>127.0.0.1</code>) port <code>8000</code>, you can adapt the default settings.</p> <pre><code>pyreadstore.Client(config_dir: str = '~/.readstore',  # Directory containing ReadStore credentials\n                  username: str | None = None,        # Username\n                  token : str | None = None,          # Token\n                  host: str = 'http://localhost',     # Hostname / IP of ReadStore server\n                  return_type: str = 'pandas',        # Default return types, can be pandas or json\n                  port: int = 8000,                   # Server Port Number\n                  fastq_extensions: List[str] = ['.fastq','.fastq.gz','.fq','.fq.gz']) \n                  # Accepted FASTQ file extensions for upload validation \n</code></pre> <p>Is is possible to set userame, token, server endpoint and fastq extensions using the listed environment variables.  The enironment variables precede over other client configurations.</p> <ul> <li><code>READSTORE_USERNAME</code> (username)</li> <li><code>READSTORE_TOKEN</code> (token)</li> <li><code>READSTORE_ENDPOINT_URL</code> (<code>http://host:post</code>, e.g. <code>http://localhost:8000</code>)</li> <li><code>READSTORE_FASTQ_EXTENSIONS</code> (fastq_extensions, <code>'.fastq',.fastq.gz,.fq,.fq.gz'</code>)</li> </ul> <p>Possible errors</p> <pre><code>- Connection Error:     If no ReadStore server was found at the provided endpoint\n- Authentication Error: If provided username or token are not found\n- No Permission to Upload/Delete FASTQ/ProData: User has no [Staging Permissions]\n</code></pre>"},{"location":"readme/#access-datasets","title":"Access Datasets","text":"<pre><code># List ReadStore Datasets\n\nrs_client.list(project_id: int | None = None,   # Filter datasets for project with id `project_id`\n              project_name: str | None = None,  # Filter datasets for project with name `project_name`\n               return_type: str | None = None   # Return pd.DataFrame or JSON type\n               ) -&gt; pd.DataFrame | List[dict]\n\n# Get ReadStore Dataset Details\n# Provide dataset_id OR dataset_name\n\nrs_client.get(dataset_id: int| None = None,     # Get dataset with id `dataset_id`\n              dataset_name: str | None = None,  # Filter datasets with name `dataset_name`\n              return_type: str | None = None    # Return pd.Series or json(dict)\n              ) -&gt; pd.Series | dict\n\n# Get FASTQ file data for a dataset\n# Provide dataset_id OR dataset_name\n\nrs_client.get_fastq(dataset_id: int| None = None,    # Get fastq data for dataset with id `dataset_id`\n                  dataset_name: str | None = None,   # Get fastq data for dataset `dataset_name`\n                  return_type: str | None = None     # Return pd.Series or json(dict)\n                  ) -&gt; pd.DataFrame | List[dict]\n\n# Return metadata for datasets in a dedicated pandas dataframe\n# Metadata keys are pivoted as column, and values as rows \n\nrs_client.list_metadata(project_id: int | None = None,   # Subset by project_id\n                        project_name: str | None = None  # Subset by project_name\n                        ) -&gt; pd.DataFrame:\n\n</code></pre>"},{"location":"readme/#edit-datasets","title":"Edit Datasets","text":"<p>NOTE Editing methods as create or delete require <code>Staging Permission</code> authorization.</p> <p>When creating datasets, the <code>name</code> argument and <code>metadata</code> dictionary are checked for consistency: Each must not be empty, contain only alphanumeric characters (plus _-.@). Metadata keys must not contain reserved keywords (listed below).</p> <pre><code># Create an empty Dataset, without FASTQ files attached\n\n# Name must be unique in Database\n# Optionally define Project IDs and/or Project names to attach Dataset to.  \n\nrs_client.create(dataset_name: str,                       # Set name\n                 description: str = '',           # Set description. Defaults to ''.\n                 project_ids: List[int] = [],     # Set project_ids. Defaults to [].\n                 project_names: List[str] = [],   # Set project_names. Defaults to [].\n                 metadata: dict = {})              # Set metadata. Defaults to {}.\n\n# Update a Dataset\n# Dataset_id must be provided to define the dataset to update.\n# Only arguments where a new values is specied will be updated.\n# Argument with None value remain unaltered.\n\nrs_client.update(dataset_id: int,                 # Set ID to update\n                dataset_name: str | None = None,  # Updated name (optional)\n                description: str | None = None,   # Updated description (optional)\n                project_ids: List[int] | None = None,   # Updated project_ids (optional)\n                project_names: List[str] | None = None, # Updated project_names (optional)\n                metadata: dict | None = None,           # Updated metadata (optional)\n\n# Provide empty project_ids or project_names list [] to unset all associated projects\n\n# Delete Dataset (and attached FASTQ files)\n# Either dataset_id or dataset_name argument must be provided\n\nrs_client.delete(dataset_id: int | None = None,   # Delete by ID. Defaults to None.\n                 dataset_name: str | None = None)  # Delete by Name. Defaults to None.\n</code></pre>"},{"location":"readme/#access-projects","title":"Access Projects","text":"<pre><code># List ReadStore Projects\n\nrs_client.list_projects(return_type: str | None = None   # Return pd.DataFrame or JSON type\n                        ) -&gt; pd.DataFrame | List[dict]\n\n# Get ReadStore Project Details\n# Provide project_id OR project_name\n\nrs_client.get_project(project_id: int| None = None,     # Get dataset with id `project_id`\n                      project_name: str | None = None,  # Filter datasets with name `project_name`\n                      return_type: str | None = None    # Return pd.Series or json(dict)\n                      ) -&gt; pd.Series | dict\n\n# Return metadata for datasets in a dedicated pandas dataframe\n# Metadata keys are pivoted as column, and values as rows \n\nrs_client.list_projects_metadata() -&gt; pd.DataFrame:\n\n</code></pre>"},{"location":"readme/#edit-projects","title":"Edit Projects","text":"<p>NOTE Editing methods as create or delete require <code>Staging Permission</code> authorization. </p> <p>When creating datasets, the <code>name</code> argument and <code>metadata</code> dictionary are checked for consistency: Each must not be empty, contain only alphanumeric characters (plus _-.@). Metadata keys must not contain reserved keywords (listed below).</p> <pre><code># Create ReadStore Project\n\n# name must be unique in Database\n# dataset_metadata_keys can be attached and will be set as default metadata keys for attached datasets\n\nrs_client.create_project(project_name: str,                       # Set Project name\n                         description: str = '',           # Set Project description. Defaults to ''.\n                         metadata: dict = {},             # Set Project metadata. Defaults to {}.\n                         dataset_metadata_keys: List[str] = [])  # Set dataset metadata keys. Defaults to [].\n\n# Update a Project\n# Project_id must be provided to define the project to update.\n# Only arguments where a new values is specied will be updated.\n# Argument with None value remain unaltered.\n\nrs_client.update_project(project_id: int,                # Set project id to update\n                         project_name: str | None = None, # Updated name (optional)\n                         description: str | None = None,  # Updated description (optional)\n                         metadata: dict | None = None,    # Updated metadata (optional)\n                         dataset_metadata_keys: List[str] | None = None) # Updated metadata keys (optional)\n\n# Delete ReadStore Project\n# Either project_id or project_name argument must be provided\n\nrs_client.delete_project(project_id: int | None = None,    # Delete by ID. Defaults to None.\n                         project_name: str | None = None)  # Delete by Name. Defaults to None.\n</code></pre>"},{"location":"readme/#access-processed-data","title":"Access Processed Data","text":"<pre><code># Upload Processed Data\n\nrs_client.upload_pro_data(name: str,                # Name of ProData\n                        pro_data_file: str,         # Set ProData file path\n                        data_type: str,             # Set ProData data type\n                        description: str = '',      # Description for ProData\n                        metadata: dict = {},        # MetaData\n                        dataset_id: int | None = None,  # Dataset ID to assign ProData to\n                        dataset_name: str | None = None)# Dataset Name to assign ProData to\n\n# Must provide dataset_id or dataset_name\n\n# List and filter Processed Data\n\nrs_client.list_pro_data(project_id: int | None = None,      # Filter by Project ID\n                        project_name: str | None = None,    # Filter by Project Name\n                        dataset_id: int | None = None,      # Filter by Dataset ID\n                        dataset_name: str | None = None,    # Filter by Dataset Name\n                        name: str | None = None,            # Filter by ProData name\n                        data_type: str | None = None,       # Filter by ProData data type\n                        include_archived: bool = False,     # Include archived\n                        return_type: str | None = None) -&gt; pd.DataFrame | List[dict]\n\n# Get individual ProData entry\n\nrs_client.get_pro_data(pro_data_id: int | None = None,  # Get ProData by ID\n                        dataset_id: int | None = None,  # Get ProData by Dataset ID\n                        dataset_name: str | None = None, # Get ProData by Dataset Name\n                        name: str | None = None,        # Get ProData by Name ID\n                        version: int | None = None,     # Get specific verion, None returns latest valid version\n                        return_type: str | None = None) -&gt; pd.Series | dict\n\n# Provide ID or Name + Dataset ID/Name\n\n# Get metadata from ProData entries\n\nrs_client.list_pro_data_metadata(project_id: int | None = None, # Subset by project ID\n                                project_name: str | None = None, # Subset by project name\n                                dataset_id: int | None = None,   # Subset by Dataset ID\n                                dataset_name: str | None = None, # Subset by Dataset Name\n                                name: str | None = None,         # Subset by ProData Name\n                                data_type: str | None = None,    # Subset by ProData Type\n                                include_archived: bool = False  # Include Archived entries\n                                ) -&gt; pd.DataFrame\n\n# Delete ProData entry\n\nrs_client.delete_pro_data(pro_data_id: int | None = None,   # Delete by ProData ID\n                        dataset_id: int | None = None,      # Delete by Dataset ID\n                        dataset_name: str | None = None,    # Delete by Dataset Name\n                        name: str | None = None,            # Delete by name\n                        version: int | None = None):        # Delete specific version\n\n# Provide ID or Name + Dataset ID/Name for delete\n</code></pre>"},{"location":"readme/#download-attachments","title":"Download Attachments","text":"<pre><code># Download project attachment file from ReadStore Database \n\nrs_client.download_project_attachment(attachment_name: str,            # name of attachment file\n                                      project_id: int | None = None,   # project id with attachment\n                                      project_name: str | None = None, # project name with attachment\n                                      outpath: str | None = None)      # Path to download file to\n\n# Download dataset attachment file from ReadStore Database \n\nrs_client.download_attachment(attachment_name: str,             # name of attachment file\n                              dataset_id: int | None = None,    # datatset id with attachment\n                              dataset_name: str | None = None,  # datatset name with attachment\n                              outpath: str | None = None)       # Path to download file to\n</code></pre>"},{"location":"readme/#upload-fastq-files","title":"Upload FASTQ files","text":"<p>Upload FASTQ files to ReadStore server. The methods checks if the FASTQ files exist and end with valid FASTQ ending.</p> <pre><code># Upload FASTQ files to ReadStore \n\nrs_client.upload_fastq(fastq : List[str] | str)  # Path of FASTQ files to upload\n</code></pre>"},{"location":"readme/#reserved-keywords","title":"Reserved keywords","text":"<p>The following keywords must not be used as metadata keys</p> <pre><code>'id','name','project','project_ids','project_names','owner_group_name','qc_passed','paired_end',\n'index_read','created','description','owner_username','fq_file_r1','fq_file_r2','fq_file_i1',\n'fq_file_i2','id_project','name_project','name_og','archived','collaborators','dataset_metadata_keys',\n'data_type','version','valid_to','upload_path','owner_username','fq_dataset','id_fq_dataset','name_fq_dataset'\n</code></pre>"},{"location":"readme/#contributing","title":"Contributing","text":"<p>Contributions make this project better! Whether you want to report a bug, improve documentation, or add new features, any help is welcomed!</p>"},{"location":"readme/#how-you-can-help","title":"How You Can Help","text":"<ul> <li>Report Bugs</li> <li>Suggest Features</li> <li>Improve Documentation</li> <li>Code Contributions</li> </ul>"},{"location":"readme/#contribution-workflow","title":"Contribution Workflow","text":"<ol> <li>Fork the repository and create a new branch for each contribution.</li> <li>Write clear, concise commit messages.</li> <li>Submit a pull request and wait for review.</li> </ol> <p>Thank you for helping make this project better!</p>"},{"location":"readme/#license","title":"License","text":"<p>The pyreadstore is licensed under an Apache 2.0 Open Source License. See the LICENSE file for more information.</p>"},{"location":"readme/#credits-and-acknowledgments","title":"Credits and Acknowledgments","text":"<p>pyreadstore is built upon the following open-source python packages and would like to thank all contributing authors, developers and partners.</p> <ul> <li>Python (https://www.djangoproject.com/)</li> <li>requests (https://requests.readthedocs.io/en/latest/)</li> <li>pydantic (https://docs.pydantic.dev/latest/)</li> <li>pandas (https://pandas.pydata.org/)</li> </ul>"},{"location":"reference/readstore/","title":"pyreadstore package","text":""},{"location":"reference/readstore/#readstore-module","title":"readstore module","text":"<p>Provides Client class and methods for pyreadstore SDK.</p> <p>Classes:</p> Name Description <code>- RSClient</code> <p>Provides client for interacting with ReadStore API</p>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client","title":"<code>Client</code>","text":"<p>A client for interacting with the ReadStore API</p> Globals <p>RETURN_TYPES: List of valid return types</p> <p>Attributes:</p> Name Type Description <code>config_dir</code> <p>Path to dir containing config</p> <code>username</code> <p>ReadStore username</p> <code>token</code> <p>ReadStore user token</p> <code>host</code> <p>Hostname of ReadStore server endpoint</p> <code>return_type</code> <p>Default return type of requests, e.g. 'pandas'</p> <code>port</code> <p>Port of ReadStore server</p> <code>fastq_extensions</code> <p>List of valid fastq extensions for upload</p> <p>Methods:</p> Name Description <code>_convert_json_to_pandas</code> <p>Convert JSON data to pandas DataFrame or Series</p> <code>_check_return_type</code> <p>Check if return type is valid</p> <code>get_return_type</code> <p>Get return type</p> <code>list</code> <p>List Datasets</p> <code>list_metadata</code> <p>List Metadata for Datasets</p> <code>get</code> <p>Get Dataset</p> <code>create</code> <p>Create Dataset</p> <code>update</code> <p>Update Dataset</p> <code>delete</code> <p>Delete Dataset</p> <code>get_fastq</code> <p>Get FASTQ files</p> <code>download_attachment</code> <p>Download Dataset attachment</p> <code>list_projects</code> <p>List Projects</p> <code>list_projects_metadata</code> <p>List Metadata for Projects</p> <code>get_project</code> <p>Get Project</p> <code>create_project</code> <p>Create Project</p> <code>update_project</code> <p>Update Project</p> <code>delete_project</code> <p>Delete Project</p> <code>download_project_attachment</code> <p>Download Project attachment</p> <code>upload_fastq</code> <p>Upload FASTQ files</p> <code>list_pro_data</code> <p>List Processed Data</p> <code>list_pro_data_metadata</code> <p>List Metadata for Processed Data</p> <code>get_pro_data</code> <p>Get Processed Data</p> <code>upload_pro_data</code> <p>Upload Processed Data</p> <code>delete_pro_data</code> <p>Delete Processed Data</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>class Client:\n    \"\"\"\n    A client for interacting with the ReadStore API\n\n    Globals:\n        RETURN_TYPES: List of valid return types\n\n    Attributes:\n        config_dir: Path to dir containing config\n        username: ReadStore username\n        token: ReadStore user token\n        host: Hostname of ReadStore server endpoint\n        return_type: Default return type of requests, e.g. 'pandas'\n        port: Port of ReadStore server\n        fastq_extensions: List of valid fastq extensions for upload\n\n    Methods:\n        _convert_json_to_pandas: Convert JSON data to pandas DataFrame or Series\n        _check_return_type: Check if return type is valid\n        get_return_type: Get return type\n        list: List Datasets\n        list_metadata: List Metadata for Datasets\n        get: Get Dataset\n        create: Create Dataset\n        update: Update Dataset\n        delete: Delete Dataset\n        get_fastq: Get FASTQ files\n        download_attachment: Download Dataset attachment\n        list_projects: List Projects\n        list_projects_metadata: List Metadata for Projects\n        get_project: Get Project\n        create_project: Create Project\n        update_project: Update Project\n        delete_project: Delete Project\n        download_project_attachment: Download Project attachment\n        upload_fastq: Upload FASTQ files\n        list_pro_data: List Processed Data\n        list_pro_data_metadata: List Metadata for Processed Data\n        get_pro_data: Get Processed Data\n        upload_pro_data: Upload Processed Data\n        delete_pro_data: Delete Processed Data\n    \"\"\"\n\n    RETURN_TYPES = [\"pandas\", \"json\"]\n\n    def __init__(\n        self,\n        config_dir: str = \"~/.readstore\",\n        username: str | None = None,\n        token: str | None = None,\n        host: str = \"http://localhost\",\n        return_type: str = \"pandas\",\n        port: int = 8000,\n        fastq_extensions: List[str] = [\".fastq\", \".fastq.gz\", \".fq\", \".fq.gz\"],\n    ):\n        \"\"\"Client constructor\n\n        Initialize the ReadStore Client and validate connection and credentials\n\n        Args:\n            config_dir: Path to dir containing config. Defaults to '~/.readstore'.\n            username: Username. Defaults to None.\n            token: User Token. Defaults to None.\n            host: Host address. Defaults to 'http://localhost'.\n            return_type: Default return type. Defaults to 'pandas'.\n            port: ReadStore Server port. Defaults to 8000.\n            fastq_extensions: Allowed extensions to fastq.\n                Defaults to ['.fastq','.fastq.gz','.fq','.fq.gz'].\n\n        Raises:\n            rsexceptions.ReadStoreError: User name and token must be provided\n            rsexceptions.ReadStoreError: Config file not found\n        \"\"\"\n\n        # Check valid return types\n        self._check_return_type(return_type)\n        self.return_type = return_type\n\n        # If username &amp; token provided, use them to initialize the client\n        if username and token:\n            endpoint_url = f\"{host}:{port}\"\n        elif username or token:\n            raise rsexceptions.ReadStoreError(\n                \"Both Username and Token must be provided\"\n            )\n        # Case load config from files\n        # TODO Add support for ENV variables ONLY\n        else:\n            if \"~\" in config_dir:\n                config_dir = os.path.expanduser(config_dir)\n            else:\n                config_dir = os.path.abspath(config_dir)\n\n            config_path = os.path.join(config_dir, \"config\")\n            if not os.path.exists(config_path):\n                raise rsexceptions.ReadStoreError(\n                    f\"Config file not found at {config_dir}\"\n                )\n\n            rs_config = configparser.ConfigParser()\n            rs_config.read(config_path)\n\n            username = rs_config.get(\"credentials\", \"username\", fallback=None)\n            token = rs_config.get(\"credentials\", \"token\", fallback=None)\n            endpoint_url = rs_config.get(\"general\", \"endpoint_url\", fallback=None)\n            fastq_extensions = rs_config.get(\n                \"general\", \"fastq_extensions\", fallback=None\n            )\n            # fastq_extensions = fastq_extensions.split(',')\n\n        # Check if ENV variables are set\n        # Overwrite config if found\n        if \"READSTORE_USERNAME\" in os.environ:\n            username = os.environ[\"READSTORE_USERNAME\"]\n        if \"READSTORE_TOKEN\" in os.environ:\n            token = os.environ[\"READSTORE_TOKEN\"]\n        if \"READSTORE_ENDPOINT_URL\" in os.environ:\n            endpoint_url = os.environ[\"READSTORE_ENDPOINT_URL\"]\n        if \"READSTORE_FASTQ_EXTENSIONS\" in os.environ:\n            fastq_extensions = os.environ[\"READSTORE_FASTQ_EXTENSIONS\"]\n            fastq_extensions = fastq_extensions.split(\",\")\n\n        self.fastq_extensions = fastq_extensions\n\n        # Initialize the client\n        self.rs_client = rsclient.RSClient(\n            username, token, endpoint_url, output_format=\"csv\"\n        )\n\n    def _convert_json_to_pandas(\n        self, json_data: List[dict] | dict, validation_class: BaseModel\n    ) -&gt; pd.DataFrame | pd.Series:\n        \"\"\"_convert_json_to_pandas\n\n        Convert JSON data to pandas DataFrame or Series\n\n        Args:\n            json_data: List or dict of JSON data\n            validation_class: Pydantic validation class\n\n        Raises:\n            rsexceptions.ReadStoreError: Invalid JSON data\n\n        Returns:\n            pd.DataFrame | pd.Series: Pandas DataFrame or Series\n        \"\"\"\n\n        if isinstance(json_data, dict):\n            if json_data == {}:\n                return pd.Series()\n            else:\n                data = validation_class(**json_data)\n                return pd.Series(data.model_dump())\n\n        elif isinstance(json_data, list):\n            # Data validation using pydantic\n            data = [validation_class(**ele) for ele in json_data]\n\n            if data == []:\n                df = pd.DataFrame(columns=validation_class.model_fields.keys())\n            else:\n                df = pd.DataFrame([ele.model_dump() for ele in data])\n\n            return df\n        else:\n            raise rsexceptions.ReadStoreError(\"Invalid JSON data\")\n\n    def _check_return_type(self, return_type: str):\n        \"\"\"_check_return_type\n\n        Check if return type is valid\n\n        Args:\n            return_type: Return type\n\n        Raises:\n            rsexceptions.ReadStoreError: Invalid return type\n        \"\"\"\n\n        if return_type not in Client.RETURN_TYPES:\n            raise rsexceptions.ReadStoreError(\n                f\"Invalid return type. Must be in {Client.RETURN_TYPES}\"\n            )\n\n    def get_return_type(self) -&gt; str:\n        \"\"\"get_return_type\"\"\"\n        return self.return_type\n\n    def list(\n        self,\n        project_id: int | None = None,\n        project_name: str | None = None,\n        return_type: str | None = None,\n    ) -&gt; pd.DataFrame | List[dict]:\n        \"\"\"List ProData\n\n        Args:\n            project_id: Filter by project_id. Defaults to None.\n            project_name: Filter by project_name. Defaults to None.\n            return_type: Specify return type. Default use return type from object.\n\n        Returns:\n            pd.DataFrame | List[dict]: List of ProData\n        \"\"\"\n\n        if return_type:\n            self._check_return_type(return_type)\n        else:\n            return_type = self.return_type\n\n        fq_datasets = self.rs_client.list_fastq_datasets(\n            project_id=project_id, project_name=project_name\n        )\n\n        if return_type == \"pandas\":\n            fq_datasets = self._convert_json_to_pandas(\n                fq_datasets, rsdataclasses.RSFqDataset\n            )\n\n        return fq_datasets\n\n    def list_metadata(\n        self, project_id: int | None = None, project_name: str | None = None\n    ) -&gt; pd.DataFrame:\n        \"\"\"List Metadata\n\n        Extract metadata from datasets and return as \n        DataFrame with metadata keys as columns\n        Non-existent metadata value will be filled with NaN\n        Order of returned dataframe will be consistent with Dataset list operation\n\n        Args:\n            project_id: Filter by project_id. Defaults to None.\n            project_name: Filter by project_name. Defaults to None.\n\n        Returns:\n            pd.DataFrame: Metadata with metadata keys as columns or empty DataFrame\n        \"\"\"\n\n        fq_datasets = self.list(\n            project_id=project_id, project_name=project_name, return_type=\"pandas\"\n        )\n\n        if fq_datasets.empty:\n            return pd.DataFrame()\n        else:\n            metadata = fq_datasets[\"metadata\"].apply(pd.Series)\n            return metadata\n\n    def get(\n        self,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n        return_type: str | None = None,\n    ) -&gt; pd.Series | dict:\n        \"\"\"Get Dataset\n\n        Args:\n            dataset_id: Select by ID. Defaults to None.\n            dataset_name: Select by Name. Defaults to None.\n            return_type: Specify return type. Default return type from Client instance.\n                Options: 'pandas', 'json'\n\n        Raises:\n            rsexceptions.ReadStoreError: Either dataset_id or dataset_name not provided\n\n        Returns:\n            pd.Series | dict: Dataset\n        \"\"\"\n\n        if (dataset_id is None) and (dataset_name is None):\n            raise rsexceptions.ReadStoreError(\n                \"Either dataset_id or dataset_name must be provided\"\n            )\n\n        if return_type:\n            self._check_return_type(return_type)\n            return_type = return_type\n        else:\n            return_type = self.return_type\n\n        fq_dataset = self.rs_client.get_fastq_dataset(\n            dataset_id=dataset_id, dataset_name=dataset_name\n        )\n\n        if return_type == \"pandas\":\n            fq_dataset = self._convert_json_to_pandas(\n                fq_dataset, rsdataclasses.RSFqDatasetDetail\n            )\n\n        return fq_dataset\n\n    def create(\n        self,\n        dataset_name: str,\n        description: str = \"\",\n        project_ids: List[int] = [],\n        project_names: List[str] = [],\n        metadata: dict = {},\n    ):\n        \"\"\"Create an empty Dataset\n\n        Create an empty dataset with the specified name, description and metadata\n        and attach it to the specified projects.\n\n        Args:\n            name: Set name\n            description: Set description. Defaults to ''.\n            project_ids: Set project_ids. Defaults to [].\n            project_names: Set project_names. Defaults to [].\n            metadata: Set metadata. Defaults to {}.\n\n        Raises:\n            rsexceptions.ReadStoreError: Dataset with name {name} already exists\n            rsexceptions.ReadStoreError: Project with id {pid} not found\n            rsexceptions.ReadStoreError: Project with name {pname} not found\n            rsexceptions.ReadStoreError: Metadata not valid\n        \"\"\"\n\n        # Should return empty pd.Series if dataset not found\n        dataset_check = self.get(dataset_name=dataset_name)\n\n        # Check if pd.Series is empty\n        if not dataset_check.empty:\n            raise rsexceptions.ReadStoreError(\n                f\"Dataset with name {dataset_name} already exists\"\n            )\n\n        # Check if project_ids and names exist\n        for pid in project_ids:\n            project_check = self.get_project(project_id=pid)\n            if project_check.empty:\n                raise rsexceptions.ReadStoreError(f\"Project with id {pid} not found\")\n        # Check if project names exist\n        for pname in project_names:\n            project_check = self.get_project(project_name=pname)\n            if project_check.empty:\n                raise rsexceptions.ReadStoreError(\n                    f\"Project with name {pname} not found\"\n                )\n\n        self.rs_client.create_fastq_dataset(\n            name=dataset_name,\n            description=description,\n            qc_passed=False,\n            paired_end=False,\n            index_read=False,\n            project_ids=project_ids,\n            project_names=project_names,\n            metadata=metadata,\n            fq_file_i1_id=None,\n            fq_file_i2_id=None,\n            fq_file_r1_id=None,\n            fq_file_r2_id=None,\n        )\n\n    def update(\n        self,\n        dataset_id: int,\n        dataset_name: str | None = None,\n        description: str | None = None,\n        project_ids: List[int] | None = None,\n        project_names: List[str] | None = None,\n        metadata: dict | None = None,\n    ):\n        \"\"\"Update Dataset\n\n        Update attributes of a Dataset\n        Dataset ID must be provided to identify the dataset to update.\n        If no update values are provided, existing values will be maintained.\n\n        Args:\n            dataset_id: Dataset ID to update\n            dataset_name: Updated Dataset name. Defaults to None.\n            description: Updated description. Defaults to None.\n            project_ids: Updated Project IDs. Defaults to None.\n            project_names: Updated Project Names. Defaults to None.\n            metadata: Updated Metadata. Defaults to None.\n\n        Raises:\n            rsexceptions.ReadStoreError: Dataset not found\n            rsexceptions.ReadStoreError: Project with defined id not found\n            rsexceptions.ReadStoreError: Project with defined name not found\n        \"\"\"\n\n        # Get the dataset // pop id\n        dataset = self.get(dataset_id=dataset_id, return_type=\"json\")\n\n        if dataset == {}:\n            raise rsexceptions.ReadStoreError(\"Dataset not found\")\n\n        project_ids_new = None\n        project_names_new = None\n\n        # If both project_ids and project_names are None, take over existing values\n        if (project_ids is None) and (project_names is None):\n            project_ids_new = dataset[\"project_ids\"]\n            project_names_new = dataset[\"project_names\"]\n\n        # Check if project_ids and names exist\n        # Project IDs and Names can be None, Empty list of None (ignore)\n        # In None case use existing values\n        if project_ids:\n            for pid in project_ids:\n                project_check = self.get_project(project_id=pid)\n                if project_check.empty:\n                    raise rsexceptions.ReadStoreError(\n                        f\"Project with id {pid} not found\"\n                    )\n            else:\n                project_ids_new = project_ids\n\n        # Check if project names exist\n        if project_names:\n            for pname in project_names:\n                project_check = self.get_project(project_name=pname)\n                if project_check.empty:\n                    raise rsexceptions.ReadStoreError(\n                        f\"Project with name {pname} not found\"\n                    )\n            else:\n                project_names_new = project_names\n\n        if project_ids_new is None:\n            project_ids_new = []\n        if project_names_new is None:\n            project_names_new = []\n\n        # Create new dataset update dict\n        # If update values are defined, use them, else use existing values\n        dataset_update = {\n            \"dataset_id\": dataset_id,\n            \"name\": dataset_name if dataset_name else dataset[\"name\"],\n            \"description\": description if description else dataset[\"description\"],\n            \"project_ids\": project_ids_new,\n            \"project_names\": project_names_new,\n            \"metadata\": metadata if metadata else dataset[\"metadata\"],\n            \"qc_passed\": dataset[\"qc_passed\"],\n            \"paired_end\": dataset[\"paired_end\"],\n            \"index_read\": dataset[\"index_read\"],\n            \"fq_file_i1_id\": dataset[\"fq_file_i1\"],\n            \"fq_file_i2_id\": dataset[\"fq_file_i2\"],\n            \"fq_file_r1_id\": dataset[\"fq_file_r1\"],\n            \"fq_file_r2_id\": dataset[\"fq_file_r2\"],\n        }\n\n        print(dataset_update)\n\n        self.rs_client.update_fastq_dataset(**dataset_update)\n\n\n    def delete(self, dataset_id: int | None = None, dataset_name: str | None = None):\n        \"\"\"Delete Dataset\n\n        Delete dataset by ID or Name. Either must be provided.\n\n        Args:\n            dataset_id: Delete by ID. Defaults to None.\n            dataset_name: Delete by Name. Defaults to None.\n\n        Raises:\n            rsexceptions.ReadStoreError: Either dataset_id or dataset_name not provided\n            rsexceptions.ReadStoreError: Dataset not found\n        \"\"\"\n\n        if (dataset_id is None) and (dataset_name is None):\n            raise rsexceptions.ReadStoreError(\n                \"Either dataset_id or dataset_name must be provided\"\n            )\n\n        if dataset_id:\n            dataset = self.get(dataset_id=dataset_id)\n            if dataset.empty:\n                raise rsexceptions.ReadStoreError(\"Dataset not found\")\n        if dataset_name:\n            dataset = self.get(dataset_name=dataset_name)\n            if dataset.empty:\n                raise rsexceptions.ReadStoreError(\"Dataset not found\")\n            else:\n                dataset_id = int(dataset[\"id\"])\n\n        self.rs_client.delete_fastq_dataset(dataset_id)\n\n    def get_fastq(\n        self,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n        return_type: str | None = None,\n    ) -&gt; pd.DataFrame | List[dict]:\n        \"\"\"Get FASTQ files\n\n        Get FASTQ files by dataset_id or dataset_name\n\n        Args:\n            dataset_id: Select by ID. Defaults to None.\n            dataset_name: Select by Name. Defaults to None.\n            return_type: Specify return type. Default use return type from object.\n\n        Raises:\n            rsexceptions.ReadStoreError: Either id or name must be provided\n\n        Returns:\n            pd.DataFrame | List[dict]: FASTQ files\n        \"\"\"\n\n        if (dataset_id is None) and (dataset_name is None):\n            raise rsexceptions.ReadStoreError(\"Either id or name must be provided\")\n\n        if return_type:\n            self._check_return_type(return_type)\n            return_type = return_type\n        else:\n            return_type = self.return_type\n\n        fq_dataset = self.rs_client.get_fastq_dataset(\n            dataset_id=dataset_id, dataset_name=dataset_name\n        )\n\n        # Check if the dataset was found\n        if fq_dataset == {}:\n            if return_type == \"pandas\":\n                return_cols = rsdataclasses.RSFqFile.model_fields.keys()\n                return pd.DataFrame(columns=return_cols)\n            else:\n                return []\n        else:\n            fq_dataset = rsdataclasses.RSFqDatasetDetail(**fq_dataset)\n\n            fq_file_ids = [\n                fq_dataset.fq_file_r1,\n                fq_dataset.fq_file_r2,\n                fq_dataset.fq_file_i1,\n                fq_dataset.fq_file_i2,\n            ]\n\n            fq_file_ids = [int(e) for e in fq_file_ids if e is not None]\n\n            fq_files = [\n                self.rs_client.get_fq_file(fq_file_id) for fq_file_id in fq_file_ids\n            ]\n\n            if return_type == \"pandas\":\n                fq_files = self._convert_json_to_pandas(\n                    fq_files, rsdataclasses.RSFqFile\n                )\n\n            return fq_files\n\n    def download_attachment(\n        self,\n        attachment_name: str,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n        outpath: str | None = None,\n    ):\n        \"\"\"Download attachment\n\n        Specify dataset_id or dataset_name\n\n        Args:\n            attachment_name: Select attachment by name\n            dataset_id: Select Dataset by ID. Defaults to None.\n            dataset_name: Select Dataset by Name. Defaults to None.\n            outpath: Set outpath. Defaults to None.\n\n        Raises:\n            rsexceptions.ReadStoreError: Dataset not found\n            rsexceptions.ReadStoreError: Attachment not found\n            rsexceptions.ReadStoreError: Output directory does not exist\n        \"\"\"\n\n        if (dataset_id is None) and (dataset_name is None):\n            raise rsexceptions.ReadStoreError(\"Either id or name must be provided\")\n\n        fq_dataset = self.rs_client.get_fastq_dataset(\n            dataset_id=dataset_id, dataset_name=dataset_name\n        )\n\n        # Check if the dataset was found\n        if fq_dataset == {}:\n            raise rsexceptions.ReadStoreError(\"Dataset not found\")\n\n        fq_dataset = rsdataclasses.RSFqDatasetDetail(**fq_dataset)\n        attachments = fq_dataset.attachments\n\n        if attachment_name not in attachments:\n            raise rsexceptions.ReadStoreError(\"Attachment not found\")\n        else:\n            if outpath is None:\n                outpath = os.getcwd()\n                outpath = os.path.join(outpath, attachment_name)\n\n            output_dirname = os.path.dirname(outpath)\n            if (output_dirname != \"\") and (not os.path.exists(output_dirname)):\n                raise rsexceptions.ReadStoreError(\n                    f\"Output directory {output_dirname} does not exist\"\n                )\n\n            self.rs_client.download_fq_dataset_attachment(\n                attachment_name, outpath, dataset_id, dataset_name\n            )\n\n    def list_projects(\n        self, return_type: str | None = None\n    ) -&gt; pd.DataFrame | List[dict]:\n        \"\"\"List Projects\n\n        Args:\n            return_type: Define return type. Defaults to None.\n\n        Returns:\n            pd.DataFrame | List[dict]: Projects\n        \"\"\"\n\n        if return_type:\n            self._check_return_type(return_type)\n            return_type = return_type\n        else:\n            return_type = self.return_type\n\n        projects = self.rs_client.list_projects()\n\n        if return_type == \"pandas\":\n            projects = self._convert_json_to_pandas(projects, rsdataclasses.RSProject)\n\n        return projects\n\n    def list_projects_metadata(self) -&gt; pd.DataFrame:\n        \"\"\"List Projects Metadata\n\n        Returns:\n            pd.DataFrame: Projects Metadata with metadata keys as columns\n        \"\"\"\n\n        projects = self.list_projects(return_type=\"pandas\")\n\n        if projects.empty:\n            return pd.DataFrame()\n        else:\n            metadata = projects[\"metadata\"].apply(pd.Series)\n            return metadata\n\n    def get_project(\n        self,\n        project_id: int | None = None,\n        project_name: str | None = None,\n        return_type: str | None = None,\n    ) -&gt; pd.Series | dict:\n        \"\"\"Get Project\n\n        Args:\n            project_id: Project ID. Defaults to None.\n            project_name: Project Name. Defaults to None.\n            return_type: Specify return type. Default return type from Client instance.\n                Options: 'pandas', 'json'\n\n        Raises:\n            rsexceptions.ReadStoreError: If project_id and project_name are not provided\n\n        Returns:\n            pd.Series | dict: Project\n        \"\"\"\n\n        if (project_id is None) and (project_name is None):\n            raise rsexceptions.ReadStoreError(\n                \"Either project_id or project_name must be provided\"\n            )\n\n        if return_type:\n            self._check_return_type(return_type)\n            return_type = return_type\n        else:\n            return_type = self.return_type\n\n        project = self.rs_client.get_project(\n            project_id=project_id, project_name=project_name\n        )\n\n        if return_type == \"pandas\":\n            project = self._convert_json_to_pandas(\n                project, rsdataclasses.RSProjectDetail\n            )\n\n        return project\n\n    def create_project(\n        self,\n        project_name: str,\n        description: str = \"\",\n        metadata: dict = {},\n        dataset_metadata_keys: List[str] = [],\n    ):\n        \"\"\"Create Project\n\n        Create a new project\n\n        Args:\n            name: Set Project name\n            description: Set Project description. Defaults to ''.\n            metadata: Set Project metadata. Defaults to {}.\n            dataset_metadata_keys: Set dataset metadata keys. Defaults to [].\n\n        Raises:\n            rsexceptions.ReadStoreError: Project with name {name} already exists\n            rsexceptions.ReadStoreError: Invalid metadata or dataset_metadata_keys\n        \"\"\"\n\n        # Check if project with name already exists\n        project_check = self.get_project(project_name=project_name)\n        if not project_check.empty:\n            raise rsexceptions.ReadStoreError(\n                f\"Project with name {project_name} already exists\"\n            )\n\n        self.rs_client.create_project(\n            project_name, description, metadata, dataset_metadata_keys\n        )\n\n    def update_project(\n        self,\n        project_id: int,\n        project_name: str | None = None,\n        description: str | None = None,\n        metadata: dict | None = None,\n        dataset_metadata_keys: List[str] | None = None,\n    ):\n        \"\"\"Update Project\n\n        Update Project attributes\n        Project ID must be provided to identify the Project to update.\n        If no update values are provided, existing values will be maintained.\n\n        Args:\n            project_id: Project ID to update\n            project_name: Updated Project name. Defaults to None.\n            description: Updated description. Defaults to None.\n            metadata: Updated metadata. Defaults to None.\n            dataset_metadata_keys: Updated Metadata Keys. Defaults to None.\n\n        Raises:\n            rsexceptions.ReadStoreError: Project not found\n        \"\"\"\n\n        project = self.get_project(project_id=project_id, return_type=\"json\")\n\n        if project == {}:\n            raise rsexceptions.ReadStoreError(\"Project not found\")\n\n        project_update = {\n            \"project_id\": project_id,\n            \"name\": project_name if project_name else project[\"name\"],\n            \"description\": description if description else project[\"description\"],\n            \"metadata\": metadata if metadata else project[\"metadata\"],\n            \"dataset_metadata_keys\": (\n                dataset_metadata_keys\n                if dataset_metadata_keys\n                else project[\"dataset_metadata_keys\"]\n            ),\n        }\n\n        self.rs_client.update_project(**project_update)\n\n    def delete_project(\n        self, project_id: int | None = None, project_name: str | None = None\n    ):\n        \"\"\"Delete Project\n\n        Delete Project by ID or Name. Either must be provided.\n\n        Args:\n            project_id: Delete by ID. Defaults to None.\n            project_name: Delete by Name. Defaults to None.\n\n        Raises:\n            rsexceptions.ReadStoreError: Either project_id or project_name not provided.\n            rsexceptions.ReadStoreError: Project not found\n        \"\"\"\n\n        if (project_id is None) and (project_name is None):\n            raise rsexceptions.ReadStoreError(\n                \"Either project_id or project_name must be provided\"\n            )\n\n        if project_id:\n            project = self.get_project(project_id=project_id)\n            if project.empty:\n                raise rsexceptions.ReadStoreError(\"Project not found\")\n        if project_name:\n            project = self.get_project(project_name=project_name)\n            if project.empty:\n                raise rsexceptions.ReadStoreError(\"Project not found\")\n            else:\n                project_id = int(project[\"id\"])\n\n        self.rs_client.delete_project(project_id)\n\n    def download_project_attachment(\n        self,\n        attachment_name: str,\n        project_id: int | None = None,\n        project_name: str | None = None,\n        outpath: str | None = None,\n    ):\n        \"\"\"Download Project Attachment\n\n        Specify project_id or project_name\n\n        Args:\n            attachment_name: Select attachment by name\n            project_id: Set Project ID. Defaults to None.\n            project_name: Set Project Name. Defaults to None.\n            outpath: Set outpath. Defaults to None.\n\n        Raises:\n            rsexceptions.ReadStoreError: Specify project_id or project_name\n            rsexceptions.ReadStoreError: Project not found\n            rsexceptions.ReadStoreError: Attachment not found\n            rsexceptions.ReadStoreError: Output directory does not exist\n        \"\"\"\n\n        if (project_id is None) and (project_name is None):\n            raise rsexceptions.ReadStoreError(\"Either id or name must be provided\")\n\n        project = self.rs_client.get_project(\n            project_id=project_id, project_name=project_name\n        )\n\n        # Check if the project was found\n        if project == {}:\n            raise rsexceptions.ReadStoreError(\"Project not found\")\n\n        project = rsdataclasses.RSProjectDetail(**project)\n        attachments = project.attachments\n\n        if attachment_name not in attachments:\n            raise rsexceptions.ReadStoreError(\"Attachment not found\")\n        else:\n            if outpath is None:\n                outpath = os.getcwd()\n                outpath = os.path.join(outpath, attachment_name)\n\n            output_dirname = os.path.dirname(outpath)\n            if (output_dirname != \"\") and (not os.path.exists(output_dirname)):\n                raise rsexceptions.ReadStoreError(\n                    f\"Output directory {output_dirname} does not exist\"\n                )\n\n            self.rs_client.download_project_attachment(\n                attachment_name, outpath, project_id, project_name\n            )\n\n    def upload_fastq(\n        self,\n        fastq: List[str] | str,\n        fastq_name: List[str] | str | None = None,\n        read_type: List[str] | str | None = None,\n    ):\n        \"\"\"Upload FASTQ files\n\n        Args:\n            fastq: List of FASTQ files or single FASTQ file\n            fastq_name: List or single names of FASTQ files. Defaults to None.\n            read_type: List of read_types. Defaults to None.\n\n        Raises:\n            rsexceptions.ReadStoreError: FASTQ file not found\n            rsexceptions.ReadStoreError: FASTQ file not valid\n        \"\"\"\n\n        if isinstance(fastq, str):\n            fastq = [fastq]\n        if isinstance(fastq_name, str):\n            fastq_name = [fastq_name]\n        if isinstance(read_type, str):\n            read_type = [read_type]\n\n        if fastq_name:\n            assert len(fastq) == len(\n                fastq_name\n            ), \"Number of FASTQ files and names must be equal\"\n        if read_type:\n            assert len(fastq) == len(\n                read_type\n            ), \"Number of FASTQ files and read types must be equal\"\n\n        fq_files = []\n        fq_names = []\n        fq_read_types = []\n        for ix, fq in enumerate(fastq):\n            if not os.path.exists(fq):\n                raise rsexceptions.ReadStoreError(f\"File {fq} not found\")\n            if not fq.endswith(tuple(self.fastq_extensions)):\n                raise rsexceptions.ReadStoreError(\n                    f\"File {fq} is not a valid FASTQ file\"\n                )\n            fq_files.append(os.path.abspath(fq))\n\n            if fastq_name:\n                fq_names.append(fastq_name[ix])\n            else:\n                fq_names.append(None)\n\n            if read_type:\n                fq_read_types.append(read_type[ix])\n            else:\n                fq_read_types.append(None)\n\n        for fq, fq_name, fq_read_type in zip(fq_files, fq_names, fq_read_types):\n            self.rs_client.upload_fastq(fq, fq_name, fq_read_type)\n\n    def list_pro_data(\n        self,\n        project_id: int | None = None,\n        project_name: str | None = None,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n        name: str | None = None,\n        data_type: str | None = None,\n        include_archived: bool = False,\n        return_type: str | None = None,\n    ) -&gt; pd.DataFrame | List[dict]:\n        \"\"\"List ProData\n\n        List Processed Data\n\n        Args:\n            project_id: Filter by Project ID. Defaults to None.\n            project_name: Filter by Project Name. Defaults to None.\n            dataset_id: Filter by Dataset ID. Defaults to None.\n            dataset_name: Filter by Dataset Name. Defaults to None.\n            name: Filter by name. Defaults to None.\n            data_type: Filter by data type. Defaults to None.\n            include_archived: Return archived. Defaults to False.\n            return_type: Specify return type. Default use return type from object.\n\n        Returns:\n            pd.DataFrame | List[dict]: List of ProData\n        \"\"\"\n\n        if return_type:\n            self._check_return_type(return_type)\n            return_type = return_type\n        else:\n            return_type = self.return_type\n\n        pro_data = self.rs_client.list_pro_data(\n            project_id=project_id,\n            project_name=project_name,\n            dataset_id=dataset_id,\n            dataset_name=dataset_name,\n            name=name,\n            data_type=data_type,\n            include_archived=include_archived,\n        )\n\n        if return_type == \"pandas\":\n            pro_data = self._convert_json_to_pandas(pro_data, rsdataclasses.RSProData)\n\n        return pro_data\n\n    def list_pro_data_metadata(\n        self,\n        project_id: int | None = None,\n        project_name: str | None = None,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n        name: str | None = None,\n        data_type: str | None = None,\n        include_archived: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"List ProData Metadata\n\n        Args:\n            project_id: Filter by Project ID. Defaults to None.\n            project_name: Filter by Project Name. Defaults to None.\n            dataset_id: Filter by Dataset ID. Defaults to None.\n            dataset_name: Filter by Dataset Name. Defaults to None.\n            name: Filter by name. Defaults to None.\n            data_type: Filter by data type. Defaults to None.\n            include_archived: Return archived. Defaults to False.\n        \"\"\"\n\n        pro_data = self.list_pro_data(\n            project_id=project_id,\n            project_name=project_name,\n            dataset_id=dataset_id,\n            dataset_name=dataset_name,\n            name=name,\n            data_type=data_type,\n            include_archived=include_archived,\n            return_type=\"pandas\",\n        )\n\n        if pro_data.empty:\n            return pd.DataFrame()\n        else:\n            metadata = pro_data[\"metadata\"].apply(pd.Series)\n            return metadata\n\n    def get_pro_data(\n        self,\n        pro_data_id: int | None = None,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n        name: str | None = None,\n        version: int | None = None,\n        return_type: str | None = None,\n    ) -&gt; pd.Series | dict:\n        \"\"\"Get ProData\n\n        Return ProData by ID or Name + Dataset ID/Name\n\n        Args:\n            pro_data_id: ProData ID. Defaults to None.\n            dataset_id: Dataset ID. Defaults to None.\n            dataset_name: Dataset Name. Defaults to None.\n            name: ProData Name. Defaults to None.\n            version: ProData Version. Defaults to None.\n            return_type: Specify return type. Default use return type from object.\n\n        Raises:\n            rsexceptions.ReadStoreError: Either pro_data_id or\n                name plus dataset_id/dataset_name must be provided\n\n        Returns:\n            pd.Series | dict: ProData\n        \"\"\"\n\n        if return_type:\n            self._check_return_type(return_type)\n            return_type = return_type\n        else:\n            return_type = self.return_type\n\n        if not pro_data_id:\n            if not name:\n                raise rsexceptions.ReadStoreError(\n                    \"Either pro_data_id or name + dataset_id/dataset_name required\"\n                )\n            if not dataset_id and not dataset_name:\n                raise rsexceptions.ReadStoreError(\n                    \"Either pro_data_id or name + dataset_id/dataset_name required\"\n                )\n\n        pro_data = self.rs_client.get_pro_data(\n            pro_data_id=pro_data_id,\n            name=name,\n            version=version,\n            dataset_id=dataset_id,\n            dataset_name=dataset_name,\n        )\n\n        if return_type == \"pandas\":\n            pro_data = self._convert_json_to_pandas(\n                pro_data, rsdataclasses.RSProDataDetail\n            )\n\n        return pro_data\n\n    def upload_pro_data(\n        self,\n        name: str,\n        pro_data_file: str,\n        data_type: str,\n        description: str = \"\",\n        metadata: dict = {},\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n    ):\n        \"\"\"Upload ProData\n\n        Upload ProData to ReadStore\n\n        Must provide dataset_id or dataset_name\n\n        Args:\n            name: Set ProData name\n            pro_data_file: Set ProData file path\n            data_type: Set ProData data type\n            description: Description for ProData. Defaults to ''.\n            metadata: Metadata for ProData. Defaults to {}.\n            dataset_id: Dataset ID. Defaults to None.\n            dataset_name: Dataset Name. Defaults to None.\n\n        Raises:\n            rsexceptions.ReadStoreError: Dataset not found\n            rsexceptions.ReadStoreError: Error uploading ProData\n        \"\"\"\n\n        fq_dataset = self.rs_client.get_fastq_dataset(\n            dataset_id=dataset_id, dataset_name=dataset_name\n        )\n        if fq_dataset == {}:\n            raise rsexceptions.ReadStoreError(\n                \"No dataset found to associate ProData with\"\n            )\n\n        fq_dataset_id = fq_dataset[\"id\"]\n\n        try:\n            self.rs_client.upload_pro_data(\n                name,\n                pro_data_file,\n                data_type,\n                dataset_id=fq_dataset_id,\n                metadata=metadata,\n                description=description,\n            )\n\n        except rsexceptions.ReadStoreError as e:\n            raise rsexceptions.ReadStoreError(f\"Error uploading ProData: {e.message}\")\n\n    def delete_pro_data(\n        self,\n        pro_data_id: int | None = None,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n        name: str | None = None,\n        version: int | None = None,\n    ):\n        \"\"\"Delete ProData\n\n        Delete ProData entry by ID or combination of Name + Dataset ID/Name.\n\n        Args:\n            pro_data_id: Delete by ID. Defaults to None.\n            dataset_id: Set by Dataset ID. Defaults to None.\n            dataset_name: Set by Dataset Name. Defaults to None.\n            name: Set by Name. Defaults to None.\n            version: Set version to delete.\n                Defaults to None, which deletes latest valid version.\n\n        Raises:\n            rsexceptions.ReadStoreError: Either pro_data_id or\n                name plus dataset_id/dataset_name must be provided\n            rsexceptions.ReadStoreError: Processed Data not found\n        \"\"\"\n\n        if not pro_data_id:\n            if not name:\n                raise rsexceptions.ReadStoreError(\n                    \"Either pro_data_id or name + dataset_id/dataset_name required\"\n                )\n            if not dataset_id and not dataset_name:\n                raise rsexceptions.ReadStoreError(\n                    \"Either pro_data_id or name + dataset_id/dataset_name required\"\n                )\n\n        try:\n            self.rs_client.delete_pro_data(\n                pro_data_id, name, dataset_id, dataset_name, version\n            )\n\n        except rsexceptions.ReadStoreError as e:\n            if \"ProData not found\" in e.message:\n                raise rsexceptions.ReadStoreError(\n                    \"ReadStore Error: ProData not found\\n\"\n                )\n            else:\n                raise rsexceptions.ReadStoreError(f\"ReadStore Error: {e.message}\\n\")\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.__init__","title":"<code>__init__(config_dir='~/.readstore', username=None, token=None, host='http://localhost', return_type='pandas', port=8000, fastq_extensions=['.fastq', '.fastq.gz', '.fq', '.fq.gz'])</code>","text":"<p>Client constructor</p> <p>Initialize the ReadStore Client and validate connection and credentials</p> <p>Parameters:</p> Name Type Description Default <code>config_dir</code> <code>str</code> <p>Path to dir containing config. Defaults to '~/.readstore'.</p> <code>'~/.readstore'</code> <code>username</code> <code>str | None</code> <p>Username. Defaults to None.</p> <code>None</code> <code>token</code> <code>str | None</code> <p>User Token. Defaults to None.</p> <code>None</code> <code>host</code> <code>str</code> <p>Host address. Defaults to 'http://localhost'.</p> <code>'http://localhost'</code> <code>return_type</code> <code>str</code> <p>Default return type. Defaults to 'pandas'.</p> <code>'pandas'</code> <code>port</code> <code>int</code> <p>ReadStore Server port. Defaults to 8000.</p> <code>8000</code> <code>fastq_extensions</code> <code>List[str]</code> <p>Allowed extensions to fastq. Defaults to ['.fastq','.fastq.gz','.fq','.fq.gz'].</p> <code>['.fastq', '.fastq.gz', '.fq', '.fq.gz']</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>User name and token must be provided</p> <code>ReadStoreError</code> <p>Config file not found</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def __init__(\n    self,\n    config_dir: str = \"~/.readstore\",\n    username: str | None = None,\n    token: str | None = None,\n    host: str = \"http://localhost\",\n    return_type: str = \"pandas\",\n    port: int = 8000,\n    fastq_extensions: List[str] = [\".fastq\", \".fastq.gz\", \".fq\", \".fq.gz\"],\n):\n    \"\"\"Client constructor\n\n    Initialize the ReadStore Client and validate connection and credentials\n\n    Args:\n        config_dir: Path to dir containing config. Defaults to '~/.readstore'.\n        username: Username. Defaults to None.\n        token: User Token. Defaults to None.\n        host: Host address. Defaults to 'http://localhost'.\n        return_type: Default return type. Defaults to 'pandas'.\n        port: ReadStore Server port. Defaults to 8000.\n        fastq_extensions: Allowed extensions to fastq.\n            Defaults to ['.fastq','.fastq.gz','.fq','.fq.gz'].\n\n    Raises:\n        rsexceptions.ReadStoreError: User name and token must be provided\n        rsexceptions.ReadStoreError: Config file not found\n    \"\"\"\n\n    # Check valid return types\n    self._check_return_type(return_type)\n    self.return_type = return_type\n\n    # If username &amp; token provided, use them to initialize the client\n    if username and token:\n        endpoint_url = f\"{host}:{port}\"\n    elif username or token:\n        raise rsexceptions.ReadStoreError(\n            \"Both Username and Token must be provided\"\n        )\n    # Case load config from files\n    # TODO Add support for ENV variables ONLY\n    else:\n        if \"~\" in config_dir:\n            config_dir = os.path.expanduser(config_dir)\n        else:\n            config_dir = os.path.abspath(config_dir)\n\n        config_path = os.path.join(config_dir, \"config\")\n        if not os.path.exists(config_path):\n            raise rsexceptions.ReadStoreError(\n                f\"Config file not found at {config_dir}\"\n            )\n\n        rs_config = configparser.ConfigParser()\n        rs_config.read(config_path)\n\n        username = rs_config.get(\"credentials\", \"username\", fallback=None)\n        token = rs_config.get(\"credentials\", \"token\", fallback=None)\n        endpoint_url = rs_config.get(\"general\", \"endpoint_url\", fallback=None)\n        fastq_extensions = rs_config.get(\n            \"general\", \"fastq_extensions\", fallback=None\n        )\n        # fastq_extensions = fastq_extensions.split(',')\n\n    # Check if ENV variables are set\n    # Overwrite config if found\n    if \"READSTORE_USERNAME\" in os.environ:\n        username = os.environ[\"READSTORE_USERNAME\"]\n    if \"READSTORE_TOKEN\" in os.environ:\n        token = os.environ[\"READSTORE_TOKEN\"]\n    if \"READSTORE_ENDPOINT_URL\" in os.environ:\n        endpoint_url = os.environ[\"READSTORE_ENDPOINT_URL\"]\n    if \"READSTORE_FASTQ_EXTENSIONS\" in os.environ:\n        fastq_extensions = os.environ[\"READSTORE_FASTQ_EXTENSIONS\"]\n        fastq_extensions = fastq_extensions.split(\",\")\n\n    self.fastq_extensions = fastq_extensions\n\n    # Initialize the client\n    self.rs_client = rsclient.RSClient(\n        username, token, endpoint_url, output_format=\"csv\"\n    )\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client._check_return_type","title":"<code>_check_return_type(return_type)</code>","text":"<p>_check_return_type</p> <p>Check if return type is valid</p> <p>Parameters:</p> Name Type Description Default <code>return_type</code> <code>str</code> <p>Return type</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Invalid return type</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def _check_return_type(self, return_type: str):\n    \"\"\"_check_return_type\n\n    Check if return type is valid\n\n    Args:\n        return_type: Return type\n\n    Raises:\n        rsexceptions.ReadStoreError: Invalid return type\n    \"\"\"\n\n    if return_type not in Client.RETURN_TYPES:\n        raise rsexceptions.ReadStoreError(\n            f\"Invalid return type. Must be in {Client.RETURN_TYPES}\"\n        )\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client._convert_json_to_pandas","title":"<code>_convert_json_to_pandas(json_data, validation_class)</code>","text":"<p>_convert_json_to_pandas</p> <p>Convert JSON data to pandas DataFrame or Series</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>List[dict] | dict</code> <p>List or dict of JSON data</p> required <code>validation_class</code> <code>BaseModel</code> <p>Pydantic validation class</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Invalid JSON data</p> <p>Returns:</p> Type Description <code>DataFrame | Series</code> <p>pd.DataFrame | pd.Series: Pandas DataFrame or Series</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def _convert_json_to_pandas(\n    self, json_data: List[dict] | dict, validation_class: BaseModel\n) -&gt; pd.DataFrame | pd.Series:\n    \"\"\"_convert_json_to_pandas\n\n    Convert JSON data to pandas DataFrame or Series\n\n    Args:\n        json_data: List or dict of JSON data\n        validation_class: Pydantic validation class\n\n    Raises:\n        rsexceptions.ReadStoreError: Invalid JSON data\n\n    Returns:\n        pd.DataFrame | pd.Series: Pandas DataFrame or Series\n    \"\"\"\n\n    if isinstance(json_data, dict):\n        if json_data == {}:\n            return pd.Series()\n        else:\n            data = validation_class(**json_data)\n            return pd.Series(data.model_dump())\n\n    elif isinstance(json_data, list):\n        # Data validation using pydantic\n        data = [validation_class(**ele) for ele in json_data]\n\n        if data == []:\n            df = pd.DataFrame(columns=validation_class.model_fields.keys())\n        else:\n            df = pd.DataFrame([ele.model_dump() for ele in data])\n\n        return df\n    else:\n        raise rsexceptions.ReadStoreError(\"Invalid JSON data\")\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.create","title":"<code>create(dataset_name, description='', project_ids=[], project_names=[], metadata={})</code>","text":"<p>Create an empty Dataset</p> <p>Create an empty dataset with the specified name, description and metadata and attach it to the specified projects.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Set name</p> required <code>description</code> <code>str</code> <p>Set description. Defaults to ''.</p> <code>''</code> <code>project_ids</code> <code>List[int]</code> <p>Set project_ids. Defaults to [].</p> <code>[]</code> <code>project_names</code> <code>List[str]</code> <p>Set project_names. Defaults to [].</p> <code>[]</code> <code>metadata</code> <code>dict</code> <p>Set metadata. Defaults to {}.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Dataset with name {name} already exists</p> <code>ReadStoreError</code> <p>Project with id {pid} not found</p> <code>ReadStoreError</code> <p>Project with name {pname} not found</p> <code>ReadStoreError</code> <p>Metadata not valid</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def create(\n    self,\n    dataset_name: str,\n    description: str = \"\",\n    project_ids: List[int] = [],\n    project_names: List[str] = [],\n    metadata: dict = {},\n):\n    \"\"\"Create an empty Dataset\n\n    Create an empty dataset with the specified name, description and metadata\n    and attach it to the specified projects.\n\n    Args:\n        name: Set name\n        description: Set description. Defaults to ''.\n        project_ids: Set project_ids. Defaults to [].\n        project_names: Set project_names. Defaults to [].\n        metadata: Set metadata. Defaults to {}.\n\n    Raises:\n        rsexceptions.ReadStoreError: Dataset with name {name} already exists\n        rsexceptions.ReadStoreError: Project with id {pid} not found\n        rsexceptions.ReadStoreError: Project with name {pname} not found\n        rsexceptions.ReadStoreError: Metadata not valid\n    \"\"\"\n\n    # Should return empty pd.Series if dataset not found\n    dataset_check = self.get(dataset_name=dataset_name)\n\n    # Check if pd.Series is empty\n    if not dataset_check.empty:\n        raise rsexceptions.ReadStoreError(\n            f\"Dataset with name {dataset_name} already exists\"\n        )\n\n    # Check if project_ids and names exist\n    for pid in project_ids:\n        project_check = self.get_project(project_id=pid)\n        if project_check.empty:\n            raise rsexceptions.ReadStoreError(f\"Project with id {pid} not found\")\n    # Check if project names exist\n    for pname in project_names:\n        project_check = self.get_project(project_name=pname)\n        if project_check.empty:\n            raise rsexceptions.ReadStoreError(\n                f\"Project with name {pname} not found\"\n            )\n\n    self.rs_client.create_fastq_dataset(\n        name=dataset_name,\n        description=description,\n        qc_passed=False,\n        paired_end=False,\n        index_read=False,\n        project_ids=project_ids,\n        project_names=project_names,\n        metadata=metadata,\n        fq_file_i1_id=None,\n        fq_file_i2_id=None,\n        fq_file_r1_id=None,\n        fq_file_r2_id=None,\n    )\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.create_project","title":"<code>create_project(project_name, description='', metadata={}, dataset_metadata_keys=[])</code>","text":"<p>Create Project</p> <p>Create a new project</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Set Project name</p> required <code>description</code> <code>str</code> <p>Set Project description. Defaults to ''.</p> <code>''</code> <code>metadata</code> <code>dict</code> <p>Set Project metadata. Defaults to {}.</p> <code>{}</code> <code>dataset_metadata_keys</code> <code>List[str]</code> <p>Set dataset metadata keys. Defaults to [].</p> <code>[]</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Project with name {name} already exists</p> <code>ReadStoreError</code> <p>Invalid metadata or dataset_metadata_keys</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def create_project(\n    self,\n    project_name: str,\n    description: str = \"\",\n    metadata: dict = {},\n    dataset_metadata_keys: List[str] = [],\n):\n    \"\"\"Create Project\n\n    Create a new project\n\n    Args:\n        name: Set Project name\n        description: Set Project description. Defaults to ''.\n        metadata: Set Project metadata. Defaults to {}.\n        dataset_metadata_keys: Set dataset metadata keys. Defaults to [].\n\n    Raises:\n        rsexceptions.ReadStoreError: Project with name {name} already exists\n        rsexceptions.ReadStoreError: Invalid metadata or dataset_metadata_keys\n    \"\"\"\n\n    # Check if project with name already exists\n    project_check = self.get_project(project_name=project_name)\n    if not project_check.empty:\n        raise rsexceptions.ReadStoreError(\n            f\"Project with name {project_name} already exists\"\n        )\n\n    self.rs_client.create_project(\n        project_name, description, metadata, dataset_metadata_keys\n    )\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.delete","title":"<code>delete(dataset_id=None, dataset_name=None)</code>","text":"<p>Delete Dataset</p> <p>Delete dataset by ID or Name. Either must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>Delete by ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Delete by Name. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Either dataset_id or dataset_name not provided</p> <code>ReadStoreError</code> <p>Dataset not found</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def delete(self, dataset_id: int | None = None, dataset_name: str | None = None):\n    \"\"\"Delete Dataset\n\n    Delete dataset by ID or Name. Either must be provided.\n\n    Args:\n        dataset_id: Delete by ID. Defaults to None.\n        dataset_name: Delete by Name. Defaults to None.\n\n    Raises:\n        rsexceptions.ReadStoreError: Either dataset_id or dataset_name not provided\n        rsexceptions.ReadStoreError: Dataset not found\n    \"\"\"\n\n    if (dataset_id is None) and (dataset_name is None):\n        raise rsexceptions.ReadStoreError(\n            \"Either dataset_id or dataset_name must be provided\"\n        )\n\n    if dataset_id:\n        dataset = self.get(dataset_id=dataset_id)\n        if dataset.empty:\n            raise rsexceptions.ReadStoreError(\"Dataset not found\")\n    if dataset_name:\n        dataset = self.get(dataset_name=dataset_name)\n        if dataset.empty:\n            raise rsexceptions.ReadStoreError(\"Dataset not found\")\n        else:\n            dataset_id = int(dataset[\"id\"])\n\n    self.rs_client.delete_fastq_dataset(dataset_id)\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.delete_pro_data","title":"<code>delete_pro_data(pro_data_id=None, dataset_id=None, dataset_name=None, name=None, version=None)</code>","text":"<p>Delete ProData</p> <p>Delete ProData entry by ID or combination of Name + Dataset ID/Name.</p> <p>Parameters:</p> Name Type Description Default <code>pro_data_id</code> <code>int | None</code> <p>Delete by ID. Defaults to None.</p> <code>None</code> <code>dataset_id</code> <code>int | None</code> <p>Set by Dataset ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Set by Dataset Name. Defaults to None.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Set by Name. Defaults to None.</p> <code>None</code> <code>version</code> <code>int | None</code> <p>Set version to delete. Defaults to None, which deletes latest valid version.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Either pro_data_id or name plus dataset_id/dataset_name must be provided</p> <code>ReadStoreError</code> <p>Processed Data not found</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def delete_pro_data(\n    self,\n    pro_data_id: int | None = None,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    name: str | None = None,\n    version: int | None = None,\n):\n    \"\"\"Delete ProData\n\n    Delete ProData entry by ID or combination of Name + Dataset ID/Name.\n\n    Args:\n        pro_data_id: Delete by ID. Defaults to None.\n        dataset_id: Set by Dataset ID. Defaults to None.\n        dataset_name: Set by Dataset Name. Defaults to None.\n        name: Set by Name. Defaults to None.\n        version: Set version to delete.\n            Defaults to None, which deletes latest valid version.\n\n    Raises:\n        rsexceptions.ReadStoreError: Either pro_data_id or\n            name plus dataset_id/dataset_name must be provided\n        rsexceptions.ReadStoreError: Processed Data not found\n    \"\"\"\n\n    if not pro_data_id:\n        if not name:\n            raise rsexceptions.ReadStoreError(\n                \"Either pro_data_id or name + dataset_id/dataset_name required\"\n            )\n        if not dataset_id and not dataset_name:\n            raise rsexceptions.ReadStoreError(\n                \"Either pro_data_id or name + dataset_id/dataset_name required\"\n            )\n\n    try:\n        self.rs_client.delete_pro_data(\n            pro_data_id, name, dataset_id, dataset_name, version\n        )\n\n    except rsexceptions.ReadStoreError as e:\n        if \"ProData not found\" in e.message:\n            raise rsexceptions.ReadStoreError(\n                \"ReadStore Error: ProData not found\\n\"\n            )\n        else:\n            raise rsexceptions.ReadStoreError(f\"ReadStore Error: {e.message}\\n\")\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.delete_project","title":"<code>delete_project(project_id=None, project_name=None)</code>","text":"<p>Delete Project</p> <p>Delete Project by ID or Name. Either must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Delete by ID. Defaults to None.</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Delete by Name. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Either project_id or project_name not provided.</p> <code>ReadStoreError</code> <p>Project not found</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def delete_project(\n    self, project_id: int | None = None, project_name: str | None = None\n):\n    \"\"\"Delete Project\n\n    Delete Project by ID or Name. Either must be provided.\n\n    Args:\n        project_id: Delete by ID. Defaults to None.\n        project_name: Delete by Name. Defaults to None.\n\n    Raises:\n        rsexceptions.ReadStoreError: Either project_id or project_name not provided.\n        rsexceptions.ReadStoreError: Project not found\n    \"\"\"\n\n    if (project_id is None) and (project_name is None):\n        raise rsexceptions.ReadStoreError(\n            \"Either project_id or project_name must be provided\"\n        )\n\n    if project_id:\n        project = self.get_project(project_id=project_id)\n        if project.empty:\n            raise rsexceptions.ReadStoreError(\"Project not found\")\n    if project_name:\n        project = self.get_project(project_name=project_name)\n        if project.empty:\n            raise rsexceptions.ReadStoreError(\"Project not found\")\n        else:\n            project_id = int(project[\"id\"])\n\n    self.rs_client.delete_project(project_id)\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.download_attachment","title":"<code>download_attachment(attachment_name, dataset_id=None, dataset_name=None, outpath=None)</code>","text":"<p>Download attachment</p> <p>Specify dataset_id or dataset_name</p> <p>Parameters:</p> Name Type Description Default <code>attachment_name</code> <code>str</code> <p>Select attachment by name</p> required <code>dataset_id</code> <code>int | None</code> <p>Select Dataset by ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Select Dataset by Name. Defaults to None.</p> <code>None</code> <code>outpath</code> <code>str | None</code> <p>Set outpath. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Dataset not found</p> <code>ReadStoreError</code> <p>Attachment not found</p> <code>ReadStoreError</code> <p>Output directory does not exist</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def download_attachment(\n    self,\n    attachment_name: str,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    outpath: str | None = None,\n):\n    \"\"\"Download attachment\n\n    Specify dataset_id or dataset_name\n\n    Args:\n        attachment_name: Select attachment by name\n        dataset_id: Select Dataset by ID. Defaults to None.\n        dataset_name: Select Dataset by Name. Defaults to None.\n        outpath: Set outpath. Defaults to None.\n\n    Raises:\n        rsexceptions.ReadStoreError: Dataset not found\n        rsexceptions.ReadStoreError: Attachment not found\n        rsexceptions.ReadStoreError: Output directory does not exist\n    \"\"\"\n\n    if (dataset_id is None) and (dataset_name is None):\n        raise rsexceptions.ReadStoreError(\"Either id or name must be provided\")\n\n    fq_dataset = self.rs_client.get_fastq_dataset(\n        dataset_id=dataset_id, dataset_name=dataset_name\n    )\n\n    # Check if the dataset was found\n    if fq_dataset == {}:\n        raise rsexceptions.ReadStoreError(\"Dataset not found\")\n\n    fq_dataset = rsdataclasses.RSFqDatasetDetail(**fq_dataset)\n    attachments = fq_dataset.attachments\n\n    if attachment_name not in attachments:\n        raise rsexceptions.ReadStoreError(\"Attachment not found\")\n    else:\n        if outpath is None:\n            outpath = os.getcwd()\n            outpath = os.path.join(outpath, attachment_name)\n\n        output_dirname = os.path.dirname(outpath)\n        if (output_dirname != \"\") and (not os.path.exists(output_dirname)):\n            raise rsexceptions.ReadStoreError(\n                f\"Output directory {output_dirname} does not exist\"\n            )\n\n        self.rs_client.download_fq_dataset_attachment(\n            attachment_name, outpath, dataset_id, dataset_name\n        )\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.download_project_attachment","title":"<code>download_project_attachment(attachment_name, project_id=None, project_name=None, outpath=None)</code>","text":"<p>Download Project Attachment</p> <p>Specify project_id or project_name</p> <p>Parameters:</p> Name Type Description Default <code>attachment_name</code> <code>str</code> <p>Select attachment by name</p> required <code>project_id</code> <code>int | None</code> <p>Set Project ID. Defaults to None.</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Set Project Name. Defaults to None.</p> <code>None</code> <code>outpath</code> <code>str | None</code> <p>Set outpath. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Specify project_id or project_name</p> <code>ReadStoreError</code> <p>Project not found</p> <code>ReadStoreError</code> <p>Attachment not found</p> <code>ReadStoreError</code> <p>Output directory does not exist</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def download_project_attachment(\n    self,\n    attachment_name: str,\n    project_id: int | None = None,\n    project_name: str | None = None,\n    outpath: str | None = None,\n):\n    \"\"\"Download Project Attachment\n\n    Specify project_id or project_name\n\n    Args:\n        attachment_name: Select attachment by name\n        project_id: Set Project ID. Defaults to None.\n        project_name: Set Project Name. Defaults to None.\n        outpath: Set outpath. Defaults to None.\n\n    Raises:\n        rsexceptions.ReadStoreError: Specify project_id or project_name\n        rsexceptions.ReadStoreError: Project not found\n        rsexceptions.ReadStoreError: Attachment not found\n        rsexceptions.ReadStoreError: Output directory does not exist\n    \"\"\"\n\n    if (project_id is None) and (project_name is None):\n        raise rsexceptions.ReadStoreError(\"Either id or name must be provided\")\n\n    project = self.rs_client.get_project(\n        project_id=project_id, project_name=project_name\n    )\n\n    # Check if the project was found\n    if project == {}:\n        raise rsexceptions.ReadStoreError(\"Project not found\")\n\n    project = rsdataclasses.RSProjectDetail(**project)\n    attachments = project.attachments\n\n    if attachment_name not in attachments:\n        raise rsexceptions.ReadStoreError(\"Attachment not found\")\n    else:\n        if outpath is None:\n            outpath = os.getcwd()\n            outpath = os.path.join(outpath, attachment_name)\n\n        output_dirname = os.path.dirname(outpath)\n        if (output_dirname != \"\") and (not os.path.exists(output_dirname)):\n            raise rsexceptions.ReadStoreError(\n                f\"Output directory {output_dirname} does not exist\"\n            )\n\n        self.rs_client.download_project_attachment(\n            attachment_name, outpath, project_id, project_name\n        )\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.get","title":"<code>get(dataset_id=None, dataset_name=None, return_type=None)</code>","text":"<p>Get Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>Select by ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Select by Name. Defaults to None.</p> <code>None</code> <code>return_type</code> <code>str | None</code> <p>Specify return type. Default return type from Client instance. Options: 'pandas', 'json'</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Either dataset_id or dataset_name not provided</p> <p>Returns:</p> Type Description <code>Series | dict</code> <p>pd.Series | dict: Dataset</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def get(\n    self,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    return_type: str | None = None,\n) -&gt; pd.Series | dict:\n    \"\"\"Get Dataset\n\n    Args:\n        dataset_id: Select by ID. Defaults to None.\n        dataset_name: Select by Name. Defaults to None.\n        return_type: Specify return type. Default return type from Client instance.\n            Options: 'pandas', 'json'\n\n    Raises:\n        rsexceptions.ReadStoreError: Either dataset_id or dataset_name not provided\n\n    Returns:\n        pd.Series | dict: Dataset\n    \"\"\"\n\n    if (dataset_id is None) and (dataset_name is None):\n        raise rsexceptions.ReadStoreError(\n            \"Either dataset_id or dataset_name must be provided\"\n        )\n\n    if return_type:\n        self._check_return_type(return_type)\n        return_type = return_type\n    else:\n        return_type = self.return_type\n\n    fq_dataset = self.rs_client.get_fastq_dataset(\n        dataset_id=dataset_id, dataset_name=dataset_name\n    )\n\n    if return_type == \"pandas\":\n        fq_dataset = self._convert_json_to_pandas(\n            fq_dataset, rsdataclasses.RSFqDatasetDetail\n        )\n\n    return fq_dataset\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.get_fastq","title":"<code>get_fastq(dataset_id=None, dataset_name=None, return_type=None)</code>","text":"<p>Get FASTQ files</p> <p>Get FASTQ files by dataset_id or dataset_name</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>Select by ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Select by Name. Defaults to None.</p> <code>None</code> <code>return_type</code> <code>str | None</code> <p>Specify return type. Default use return type from object.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Either id or name must be provided</p> <p>Returns:</p> Type Description <code>DataFrame | List[dict]</code> <p>pd.DataFrame | List[dict]: FASTQ files</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def get_fastq(\n    self,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    return_type: str | None = None,\n) -&gt; pd.DataFrame | List[dict]:\n    \"\"\"Get FASTQ files\n\n    Get FASTQ files by dataset_id or dataset_name\n\n    Args:\n        dataset_id: Select by ID. Defaults to None.\n        dataset_name: Select by Name. Defaults to None.\n        return_type: Specify return type. Default use return type from object.\n\n    Raises:\n        rsexceptions.ReadStoreError: Either id or name must be provided\n\n    Returns:\n        pd.DataFrame | List[dict]: FASTQ files\n    \"\"\"\n\n    if (dataset_id is None) and (dataset_name is None):\n        raise rsexceptions.ReadStoreError(\"Either id or name must be provided\")\n\n    if return_type:\n        self._check_return_type(return_type)\n        return_type = return_type\n    else:\n        return_type = self.return_type\n\n    fq_dataset = self.rs_client.get_fastq_dataset(\n        dataset_id=dataset_id, dataset_name=dataset_name\n    )\n\n    # Check if the dataset was found\n    if fq_dataset == {}:\n        if return_type == \"pandas\":\n            return_cols = rsdataclasses.RSFqFile.model_fields.keys()\n            return pd.DataFrame(columns=return_cols)\n        else:\n            return []\n    else:\n        fq_dataset = rsdataclasses.RSFqDatasetDetail(**fq_dataset)\n\n        fq_file_ids = [\n            fq_dataset.fq_file_r1,\n            fq_dataset.fq_file_r2,\n            fq_dataset.fq_file_i1,\n            fq_dataset.fq_file_i2,\n        ]\n\n        fq_file_ids = [int(e) for e in fq_file_ids if e is not None]\n\n        fq_files = [\n            self.rs_client.get_fq_file(fq_file_id) for fq_file_id in fq_file_ids\n        ]\n\n        if return_type == \"pandas\":\n            fq_files = self._convert_json_to_pandas(\n                fq_files, rsdataclasses.RSFqFile\n            )\n\n        return fq_files\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.get_pro_data","title":"<code>get_pro_data(pro_data_id=None, dataset_id=None, dataset_name=None, name=None, version=None, return_type=None)</code>","text":"<p>Get ProData</p> <p>Return ProData by ID or Name + Dataset ID/Name</p> <p>Parameters:</p> Name Type Description Default <code>pro_data_id</code> <code>int | None</code> <p>ProData ID. Defaults to None.</p> <code>None</code> <code>dataset_id</code> <code>int | None</code> <p>Dataset ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Dataset Name. Defaults to None.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>ProData Name. Defaults to None.</p> <code>None</code> <code>version</code> <code>int | None</code> <p>ProData Version. Defaults to None.</p> <code>None</code> <code>return_type</code> <code>str | None</code> <p>Specify return type. Default use return type from object.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Either pro_data_id or name plus dataset_id/dataset_name must be provided</p> <p>Returns:</p> Type Description <code>Series | dict</code> <p>pd.Series | dict: ProData</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def get_pro_data(\n    self,\n    pro_data_id: int | None = None,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    name: str | None = None,\n    version: int | None = None,\n    return_type: str | None = None,\n) -&gt; pd.Series | dict:\n    \"\"\"Get ProData\n\n    Return ProData by ID or Name + Dataset ID/Name\n\n    Args:\n        pro_data_id: ProData ID. Defaults to None.\n        dataset_id: Dataset ID. Defaults to None.\n        dataset_name: Dataset Name. Defaults to None.\n        name: ProData Name. Defaults to None.\n        version: ProData Version. Defaults to None.\n        return_type: Specify return type. Default use return type from object.\n\n    Raises:\n        rsexceptions.ReadStoreError: Either pro_data_id or\n            name plus dataset_id/dataset_name must be provided\n\n    Returns:\n        pd.Series | dict: ProData\n    \"\"\"\n\n    if return_type:\n        self._check_return_type(return_type)\n        return_type = return_type\n    else:\n        return_type = self.return_type\n\n    if not pro_data_id:\n        if not name:\n            raise rsexceptions.ReadStoreError(\n                \"Either pro_data_id or name + dataset_id/dataset_name required\"\n            )\n        if not dataset_id and not dataset_name:\n            raise rsexceptions.ReadStoreError(\n                \"Either pro_data_id or name + dataset_id/dataset_name required\"\n            )\n\n    pro_data = self.rs_client.get_pro_data(\n        pro_data_id=pro_data_id,\n        name=name,\n        version=version,\n        dataset_id=dataset_id,\n        dataset_name=dataset_name,\n    )\n\n    if return_type == \"pandas\":\n        pro_data = self._convert_json_to_pandas(\n            pro_data, rsdataclasses.RSProDataDetail\n        )\n\n    return pro_data\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.get_project","title":"<code>get_project(project_id=None, project_name=None, return_type=None)</code>","text":"<p>Get Project</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Project ID. Defaults to None.</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Project Name. Defaults to None.</p> <code>None</code> <code>return_type</code> <code>str | None</code> <p>Specify return type. Default return type from Client instance. Options: 'pandas', 'json'</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If project_id and project_name are not provided</p> <p>Returns:</p> Type Description <code>Series | dict</code> <p>pd.Series | dict: Project</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def get_project(\n    self,\n    project_id: int | None = None,\n    project_name: str | None = None,\n    return_type: str | None = None,\n) -&gt; pd.Series | dict:\n    \"\"\"Get Project\n\n    Args:\n        project_id: Project ID. Defaults to None.\n        project_name: Project Name. Defaults to None.\n        return_type: Specify return type. Default return type from Client instance.\n            Options: 'pandas', 'json'\n\n    Raises:\n        rsexceptions.ReadStoreError: If project_id and project_name are not provided\n\n    Returns:\n        pd.Series | dict: Project\n    \"\"\"\n\n    if (project_id is None) and (project_name is None):\n        raise rsexceptions.ReadStoreError(\n            \"Either project_id or project_name must be provided\"\n        )\n\n    if return_type:\n        self._check_return_type(return_type)\n        return_type = return_type\n    else:\n        return_type = self.return_type\n\n    project = self.rs_client.get_project(\n        project_id=project_id, project_name=project_name\n    )\n\n    if return_type == \"pandas\":\n        project = self._convert_json_to_pandas(\n            project, rsdataclasses.RSProjectDetail\n        )\n\n    return project\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.get_return_type","title":"<code>get_return_type()</code>","text":"<p>get_return_type</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def get_return_type(self) -&gt; str:\n    \"\"\"get_return_type\"\"\"\n    return self.return_type\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.list","title":"<code>list(project_id=None, project_name=None, return_type=None)</code>","text":"<p>List ProData</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Filter by project_id. Defaults to None.</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Filter by project_name. Defaults to None.</p> <code>None</code> <code>return_type</code> <code>str | None</code> <p>Specify return type. Default use return type from object.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame | List[dict]</code> <p>pd.DataFrame | List[dict]: List of ProData</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def list(\n    self,\n    project_id: int | None = None,\n    project_name: str | None = None,\n    return_type: str | None = None,\n) -&gt; pd.DataFrame | List[dict]:\n    \"\"\"List ProData\n\n    Args:\n        project_id: Filter by project_id. Defaults to None.\n        project_name: Filter by project_name. Defaults to None.\n        return_type: Specify return type. Default use return type from object.\n\n    Returns:\n        pd.DataFrame | List[dict]: List of ProData\n    \"\"\"\n\n    if return_type:\n        self._check_return_type(return_type)\n    else:\n        return_type = self.return_type\n\n    fq_datasets = self.rs_client.list_fastq_datasets(\n        project_id=project_id, project_name=project_name\n    )\n\n    if return_type == \"pandas\":\n        fq_datasets = self._convert_json_to_pandas(\n            fq_datasets, rsdataclasses.RSFqDataset\n        )\n\n    return fq_datasets\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.list_metadata","title":"<code>list_metadata(project_id=None, project_name=None)</code>","text":"<p>List Metadata</p> <p>Extract metadata from datasets and return as  DataFrame with metadata keys as columns Non-existent metadata value will be filled with NaN Order of returned dataframe will be consistent with Dataset list operation</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Filter by project_id. Defaults to None.</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Filter by project_name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Metadata with metadata keys as columns or empty DataFrame</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def list_metadata(\n    self, project_id: int | None = None, project_name: str | None = None\n) -&gt; pd.DataFrame:\n    \"\"\"List Metadata\n\n    Extract metadata from datasets and return as \n    DataFrame with metadata keys as columns\n    Non-existent metadata value will be filled with NaN\n    Order of returned dataframe will be consistent with Dataset list operation\n\n    Args:\n        project_id: Filter by project_id. Defaults to None.\n        project_name: Filter by project_name. Defaults to None.\n\n    Returns:\n        pd.DataFrame: Metadata with metadata keys as columns or empty DataFrame\n    \"\"\"\n\n    fq_datasets = self.list(\n        project_id=project_id, project_name=project_name, return_type=\"pandas\"\n    )\n\n    if fq_datasets.empty:\n        return pd.DataFrame()\n    else:\n        metadata = fq_datasets[\"metadata\"].apply(pd.Series)\n        return metadata\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.list_pro_data","title":"<code>list_pro_data(project_id=None, project_name=None, dataset_id=None, dataset_name=None, name=None, data_type=None, include_archived=False, return_type=None)</code>","text":"<p>List ProData</p> <p>List Processed Data</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Filter by Project ID. Defaults to None.</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Filter by Project Name. Defaults to None.</p> <code>None</code> <code>dataset_id</code> <code>int | None</code> <p>Filter by Dataset ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Filter by Dataset Name. Defaults to None.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Filter by name. Defaults to None.</p> <code>None</code> <code>data_type</code> <code>str | None</code> <p>Filter by data type. Defaults to None.</p> <code>None</code> <code>include_archived</code> <code>bool</code> <p>Return archived. Defaults to False.</p> <code>False</code> <code>return_type</code> <code>str | None</code> <p>Specify return type. Default use return type from object.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame | List[dict]</code> <p>pd.DataFrame | List[dict]: List of ProData</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def list_pro_data(\n    self,\n    project_id: int | None = None,\n    project_name: str | None = None,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    name: str | None = None,\n    data_type: str | None = None,\n    include_archived: bool = False,\n    return_type: str | None = None,\n) -&gt; pd.DataFrame | List[dict]:\n    \"\"\"List ProData\n\n    List Processed Data\n\n    Args:\n        project_id: Filter by Project ID. Defaults to None.\n        project_name: Filter by Project Name. Defaults to None.\n        dataset_id: Filter by Dataset ID. Defaults to None.\n        dataset_name: Filter by Dataset Name. Defaults to None.\n        name: Filter by name. Defaults to None.\n        data_type: Filter by data type. Defaults to None.\n        include_archived: Return archived. Defaults to False.\n        return_type: Specify return type. Default use return type from object.\n\n    Returns:\n        pd.DataFrame | List[dict]: List of ProData\n    \"\"\"\n\n    if return_type:\n        self._check_return_type(return_type)\n        return_type = return_type\n    else:\n        return_type = self.return_type\n\n    pro_data = self.rs_client.list_pro_data(\n        project_id=project_id,\n        project_name=project_name,\n        dataset_id=dataset_id,\n        dataset_name=dataset_name,\n        name=name,\n        data_type=data_type,\n        include_archived=include_archived,\n    )\n\n    if return_type == \"pandas\":\n        pro_data = self._convert_json_to_pandas(pro_data, rsdataclasses.RSProData)\n\n    return pro_data\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.list_pro_data_metadata","title":"<code>list_pro_data_metadata(project_id=None, project_name=None, dataset_id=None, dataset_name=None, name=None, data_type=None, include_archived=False)</code>","text":"<p>List ProData Metadata</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Filter by Project ID. Defaults to None.</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Filter by Project Name. Defaults to None.</p> <code>None</code> <code>dataset_id</code> <code>int | None</code> <p>Filter by Dataset ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Filter by Dataset Name. Defaults to None.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Filter by name. Defaults to None.</p> <code>None</code> <code>data_type</code> <code>str | None</code> <p>Filter by data type. Defaults to None.</p> <code>None</code> <code>include_archived</code> <code>bool</code> <p>Return archived. Defaults to False.</p> <code>False</code> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def list_pro_data_metadata(\n    self,\n    project_id: int | None = None,\n    project_name: str | None = None,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n    name: str | None = None,\n    data_type: str | None = None,\n    include_archived: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"List ProData Metadata\n\n    Args:\n        project_id: Filter by Project ID. Defaults to None.\n        project_name: Filter by Project Name. Defaults to None.\n        dataset_id: Filter by Dataset ID. Defaults to None.\n        dataset_name: Filter by Dataset Name. Defaults to None.\n        name: Filter by name. Defaults to None.\n        data_type: Filter by data type. Defaults to None.\n        include_archived: Return archived. Defaults to False.\n    \"\"\"\n\n    pro_data = self.list_pro_data(\n        project_id=project_id,\n        project_name=project_name,\n        dataset_id=dataset_id,\n        dataset_name=dataset_name,\n        name=name,\n        data_type=data_type,\n        include_archived=include_archived,\n        return_type=\"pandas\",\n    )\n\n    if pro_data.empty:\n        return pd.DataFrame()\n    else:\n        metadata = pro_data[\"metadata\"].apply(pd.Series)\n        return metadata\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.list_projects","title":"<code>list_projects(return_type=None)</code>","text":"<p>List Projects</p> <p>Parameters:</p> Name Type Description Default <code>return_type</code> <code>str | None</code> <p>Define return type. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame | List[dict]</code> <p>pd.DataFrame | List[dict]: Projects</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def list_projects(\n    self, return_type: str | None = None\n) -&gt; pd.DataFrame | List[dict]:\n    \"\"\"List Projects\n\n    Args:\n        return_type: Define return type. Defaults to None.\n\n    Returns:\n        pd.DataFrame | List[dict]: Projects\n    \"\"\"\n\n    if return_type:\n        self._check_return_type(return_type)\n        return_type = return_type\n    else:\n        return_type = self.return_type\n\n    projects = self.rs_client.list_projects()\n\n    if return_type == \"pandas\":\n        projects = self._convert_json_to_pandas(projects, rsdataclasses.RSProject)\n\n    return projects\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.list_projects_metadata","title":"<code>list_projects_metadata()</code>","text":"<p>List Projects Metadata</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Projects Metadata with metadata keys as columns</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def list_projects_metadata(self) -&gt; pd.DataFrame:\n    \"\"\"List Projects Metadata\n\n    Returns:\n        pd.DataFrame: Projects Metadata with metadata keys as columns\n    \"\"\"\n\n    projects = self.list_projects(return_type=\"pandas\")\n\n    if projects.empty:\n        return pd.DataFrame()\n    else:\n        metadata = projects[\"metadata\"].apply(pd.Series)\n        return metadata\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.update","title":"<code>update(dataset_id, dataset_name=None, description=None, project_ids=None, project_names=None, metadata=None)</code>","text":"<p>Update Dataset</p> <p>Update attributes of a Dataset Dataset ID must be provided to identify the dataset to update. If no update values are provided, existing values will be maintained.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int</code> <p>Dataset ID to update</p> required <code>dataset_name</code> <code>str | None</code> <p>Updated Dataset name. Defaults to None.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Updated description. Defaults to None.</p> <code>None</code> <code>project_ids</code> <code>List[int] | None</code> <p>Updated Project IDs. Defaults to None.</p> <code>None</code> <code>project_names</code> <code>List[str] | None</code> <p>Updated Project Names. Defaults to None.</p> <code>None</code> <code>metadata</code> <code>dict | None</code> <p>Updated Metadata. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Dataset not found</p> <code>ReadStoreError</code> <p>Project with defined id not found</p> <code>ReadStoreError</code> <p>Project with defined name not found</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def update(\n    self,\n    dataset_id: int,\n    dataset_name: str | None = None,\n    description: str | None = None,\n    project_ids: List[int] | None = None,\n    project_names: List[str] | None = None,\n    metadata: dict | None = None,\n):\n    \"\"\"Update Dataset\n\n    Update attributes of a Dataset\n    Dataset ID must be provided to identify the dataset to update.\n    If no update values are provided, existing values will be maintained.\n\n    Args:\n        dataset_id: Dataset ID to update\n        dataset_name: Updated Dataset name. Defaults to None.\n        description: Updated description. Defaults to None.\n        project_ids: Updated Project IDs. Defaults to None.\n        project_names: Updated Project Names. Defaults to None.\n        metadata: Updated Metadata. Defaults to None.\n\n    Raises:\n        rsexceptions.ReadStoreError: Dataset not found\n        rsexceptions.ReadStoreError: Project with defined id not found\n        rsexceptions.ReadStoreError: Project with defined name not found\n    \"\"\"\n\n    # Get the dataset // pop id\n    dataset = self.get(dataset_id=dataset_id, return_type=\"json\")\n\n    if dataset == {}:\n        raise rsexceptions.ReadStoreError(\"Dataset not found\")\n\n    project_ids_new = None\n    project_names_new = None\n\n    # If both project_ids and project_names are None, take over existing values\n    if (project_ids is None) and (project_names is None):\n        project_ids_new = dataset[\"project_ids\"]\n        project_names_new = dataset[\"project_names\"]\n\n    # Check if project_ids and names exist\n    # Project IDs and Names can be None, Empty list of None (ignore)\n    # In None case use existing values\n    if project_ids:\n        for pid in project_ids:\n            project_check = self.get_project(project_id=pid)\n            if project_check.empty:\n                raise rsexceptions.ReadStoreError(\n                    f\"Project with id {pid} not found\"\n                )\n        else:\n            project_ids_new = project_ids\n\n    # Check if project names exist\n    if project_names:\n        for pname in project_names:\n            project_check = self.get_project(project_name=pname)\n            if project_check.empty:\n                raise rsexceptions.ReadStoreError(\n                    f\"Project with name {pname} not found\"\n                )\n        else:\n            project_names_new = project_names\n\n    if project_ids_new is None:\n        project_ids_new = []\n    if project_names_new is None:\n        project_names_new = []\n\n    # Create new dataset update dict\n    # If update values are defined, use them, else use existing values\n    dataset_update = {\n        \"dataset_id\": dataset_id,\n        \"name\": dataset_name if dataset_name else dataset[\"name\"],\n        \"description\": description if description else dataset[\"description\"],\n        \"project_ids\": project_ids_new,\n        \"project_names\": project_names_new,\n        \"metadata\": metadata if metadata else dataset[\"metadata\"],\n        \"qc_passed\": dataset[\"qc_passed\"],\n        \"paired_end\": dataset[\"paired_end\"],\n        \"index_read\": dataset[\"index_read\"],\n        \"fq_file_i1_id\": dataset[\"fq_file_i1\"],\n        \"fq_file_i2_id\": dataset[\"fq_file_i2\"],\n        \"fq_file_r1_id\": dataset[\"fq_file_r1\"],\n        \"fq_file_r2_id\": dataset[\"fq_file_r2\"],\n    }\n\n    print(dataset_update)\n\n    self.rs_client.update_fastq_dataset(**dataset_update)\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.update_project","title":"<code>update_project(project_id, project_name=None, description=None, metadata=None, dataset_metadata_keys=None)</code>","text":"<p>Update Project</p> <p>Update Project attributes Project ID must be provided to identify the Project to update. If no update values are provided, existing values will be maintained.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int</code> <p>Project ID to update</p> required <code>project_name</code> <code>str | None</code> <p>Updated Project name. Defaults to None.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Updated description. Defaults to None.</p> <code>None</code> <code>metadata</code> <code>dict | None</code> <p>Updated metadata. Defaults to None.</p> <code>None</code> <code>dataset_metadata_keys</code> <code>List[str] | None</code> <p>Updated Metadata Keys. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Project not found</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def update_project(\n    self,\n    project_id: int,\n    project_name: str | None = None,\n    description: str | None = None,\n    metadata: dict | None = None,\n    dataset_metadata_keys: List[str] | None = None,\n):\n    \"\"\"Update Project\n\n    Update Project attributes\n    Project ID must be provided to identify the Project to update.\n    If no update values are provided, existing values will be maintained.\n\n    Args:\n        project_id: Project ID to update\n        project_name: Updated Project name. Defaults to None.\n        description: Updated description. Defaults to None.\n        metadata: Updated metadata. Defaults to None.\n        dataset_metadata_keys: Updated Metadata Keys. Defaults to None.\n\n    Raises:\n        rsexceptions.ReadStoreError: Project not found\n    \"\"\"\n\n    project = self.get_project(project_id=project_id, return_type=\"json\")\n\n    if project == {}:\n        raise rsexceptions.ReadStoreError(\"Project not found\")\n\n    project_update = {\n        \"project_id\": project_id,\n        \"name\": project_name if project_name else project[\"name\"],\n        \"description\": description if description else project[\"description\"],\n        \"metadata\": metadata if metadata else project[\"metadata\"],\n        \"dataset_metadata_keys\": (\n            dataset_metadata_keys\n            if dataset_metadata_keys\n            else project[\"dataset_metadata_keys\"]\n        ),\n    }\n\n    self.rs_client.update_project(**project_update)\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.upload_fastq","title":"<code>upload_fastq(fastq, fastq_name=None, read_type=None)</code>","text":"<p>Upload FASTQ files</p> <p>Parameters:</p> Name Type Description Default <code>fastq</code> <code>List[str] | str</code> <p>List of FASTQ files or single FASTQ file</p> required <code>fastq_name</code> <code>List[str] | str | None</code> <p>List or single names of FASTQ files. Defaults to None.</p> <code>None</code> <code>read_type</code> <code>List[str] | str | None</code> <p>List of read_types. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>FASTQ file not found</p> <code>ReadStoreError</code> <p>FASTQ file not valid</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def upload_fastq(\n    self,\n    fastq: List[str] | str,\n    fastq_name: List[str] | str | None = None,\n    read_type: List[str] | str | None = None,\n):\n    \"\"\"Upload FASTQ files\n\n    Args:\n        fastq: List of FASTQ files or single FASTQ file\n        fastq_name: List or single names of FASTQ files. Defaults to None.\n        read_type: List of read_types. Defaults to None.\n\n    Raises:\n        rsexceptions.ReadStoreError: FASTQ file not found\n        rsexceptions.ReadStoreError: FASTQ file not valid\n    \"\"\"\n\n    if isinstance(fastq, str):\n        fastq = [fastq]\n    if isinstance(fastq_name, str):\n        fastq_name = [fastq_name]\n    if isinstance(read_type, str):\n        read_type = [read_type]\n\n    if fastq_name:\n        assert len(fastq) == len(\n            fastq_name\n        ), \"Number of FASTQ files and names must be equal\"\n    if read_type:\n        assert len(fastq) == len(\n            read_type\n        ), \"Number of FASTQ files and read types must be equal\"\n\n    fq_files = []\n    fq_names = []\n    fq_read_types = []\n    for ix, fq in enumerate(fastq):\n        if not os.path.exists(fq):\n            raise rsexceptions.ReadStoreError(f\"File {fq} not found\")\n        if not fq.endswith(tuple(self.fastq_extensions)):\n            raise rsexceptions.ReadStoreError(\n                f\"File {fq} is not a valid FASTQ file\"\n            )\n        fq_files.append(os.path.abspath(fq))\n\n        if fastq_name:\n            fq_names.append(fastq_name[ix])\n        else:\n            fq_names.append(None)\n\n        if read_type:\n            fq_read_types.append(read_type[ix])\n        else:\n            fq_read_types.append(None)\n\n    for fq, fq_name, fq_read_type in zip(fq_files, fq_names, fq_read_types):\n        self.rs_client.upload_fastq(fq, fq_name, fq_read_type)\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.pyreadstore.Client.upload_pro_data","title":"<code>upload_pro_data(name, pro_data_file, data_type, description='', metadata={}, dataset_id=None, dataset_name=None)</code>","text":"<p>Upload ProData</p> <p>Upload ProData to ReadStore</p> <p>Must provide dataset_id or dataset_name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Set ProData name</p> required <code>pro_data_file</code> <code>str</code> <p>Set ProData file path</p> required <code>data_type</code> <code>str</code> <p>Set ProData data type</p> required <code>description</code> <code>str</code> <p>Description for ProData. Defaults to ''.</p> <code>''</code> <code>metadata</code> <code>dict</code> <p>Metadata for ProData. Defaults to {}.</p> <code>{}</code> <code>dataset_id</code> <code>int | None</code> <p>Dataset ID. Defaults to None.</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Dataset Name. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Dataset not found</p> <code>ReadStoreError</code> <p>Error uploading ProData</p> Source code in <code>pyreadstore/pyreadstore.py</code> <pre><code>def upload_pro_data(\n    self,\n    name: str,\n    pro_data_file: str,\n    data_type: str,\n    description: str = \"\",\n    metadata: dict = {},\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n):\n    \"\"\"Upload ProData\n\n    Upload ProData to ReadStore\n\n    Must provide dataset_id or dataset_name\n\n    Args:\n        name: Set ProData name\n        pro_data_file: Set ProData file path\n        data_type: Set ProData data type\n        description: Description for ProData. Defaults to ''.\n        metadata: Metadata for ProData. Defaults to {}.\n        dataset_id: Dataset ID. Defaults to None.\n        dataset_name: Dataset Name. Defaults to None.\n\n    Raises:\n        rsexceptions.ReadStoreError: Dataset not found\n        rsexceptions.ReadStoreError: Error uploading ProData\n    \"\"\"\n\n    fq_dataset = self.rs_client.get_fastq_dataset(\n        dataset_id=dataset_id, dataset_name=dataset_name\n    )\n    if fq_dataset == {}:\n        raise rsexceptions.ReadStoreError(\n            \"No dataset found to associate ProData with\"\n        )\n\n    fq_dataset_id = fq_dataset[\"id\"]\n\n    try:\n        self.rs_client.upload_pro_data(\n            name,\n            pro_data_file,\n            data_type,\n            dataset_id=fq_dataset_id,\n            metadata=metadata,\n            description=description,\n        )\n\n    except rsexceptions.ReadStoreError as e:\n        raise rsexceptions.ReadStoreError(f\"Error uploading ProData: {e.message}\")\n</code></pre>"},{"location":"reference/readstore/#rsclient-module","title":"rsclient module","text":"<p>Provides client for interacting with ReadStore API.</p> <p>Classes:</p> Name Description <code>- RSClient</code> <p>Provides client for interacting with ReadStore API</p>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient","title":"<code>RSClient</code>","text":"<p>A client for interacting with the ReadStore API</p> <p>Attributes:</p> Name Type Description <code>username</code> <p>ReadStore username</p> <code>token</code> <p>ReadStore user token</p> <code>endpoint</code> <p>The endpoint URL for the ReadStore API</p> <code>output_format</code> <p>The default output format for the client</p> <p>Methods:</p> Name Description <code>_test_server_connection</code> <p>Validate server URL</p> <code>_auth_user_token</code> <p>Validate user and token</p> <code>validate_charset</code> <p>Validate charset for query string</p> <code>validate_metadata</code> <p>Validate metadata dict</p> <code>get_output_format</code> <p>Get Output Format set for client</p> <code>upload_fastq</code> <p>Upload Fastq Files</p> <code>get_fq_file</code> <p>Get Fastq File</p> <code>list_fq_files</code> <p>List Fastq Files</p> <code>create_fq_file</code> <p>Create Fastq File</p> <code>update_fq_file</code> <p>Update Fastq File</p> <code>delete_fq_file</code> <p>Delete Fastq File</p> <code>get_fq_file_upload_path</code> <p>Get FASTQ file upload  path</p> <code>list_fastq_datasets</code> <p>List FASTQ Datasets</p> <code>get_fastq_dataset</code> <p>Get FASTQ dataset</p> <code>create_fastq_dataset</code> <p>Create Fastq Dataset</p> <code>update_fastq_dataset</code> <p>Update Fastq Dataset</p> <code>delete_fastq_dataset</code> <p>Delete Fastq Dataset</p> <code>list_projects</code> <p>List Projects</p> <code>get_project</code> <p>Get Project by id or name</p> <code>create_project</code> <p>Create Project</p> <code>update_project</code> <p>Update Project</p> <code>delete_project</code> <p>Delete Project</p> <code>download_project_attachment</code> <p>Download Project Attachments</p> <code>download_fq_dataset_attachment</code> <p>Download Fastq Attach</p> <code>upload_pro_data</code> <p>Upload Processed Data</p> <code>list_pro_data</code> <p>List Processed Data</p> <code>get_pro_data</code> <p>Get Processed Data</p> <code>delete_pro_data</code> <p>Delete Processed Data</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>class RSClient:\n    \"\"\"\n        A client for interacting with the ReadStore API\n\n        Attributes:\n            username: ReadStore username\n            token: ReadStore user token\n            endpoint: The endpoint URL for the ReadStore API\n            output_format: The default output format for the client\n\n        Methods:\n            _test_server_connection: Validate server URL\n            _auth_user_token: Validate user and token\n            validate_charset: Validate charset for query string\n            validate_metadata: Validate metadata dict\n            get_output_format: Get Output Format set for client\n            upload_fastq: Upload Fastq Files\n            get_fq_file: Get Fastq File\n            list_fq_files: List Fastq Files\n            create_fq_file: Create Fastq File\n            update_fq_file: Update Fastq File\n            delete_fq_file: Delete Fastq File\n            get_fq_file_upload_path: Get FASTQ file upload  path\n            list_fastq_datasets: List FASTQ Datasets\n            get_fastq_dataset: Get FASTQ dataset\n            create_fastq_dataset: Create Fastq Dataset\n            update_fastq_dataset: Update Fastq Dataset\n            delete_fastq_dataset: Delete Fastq Dataset\n            list_projects: List Projects\n            get_project: Get Project by id or name\n            create_project: Create Project\n            update_project: Update Project\n            delete_project: Delete Project\n            download_project_attachment: Download Project Attachments\n            download_fq_dataset_attachment: Download Fastq Attach\n            upload_pro_data: Upload Processed Data\n            list_pro_data: List Processed Data\n            get_pro_data: Get Processed Data\n            delete_pro_data: Delete Processed Data\n    \"\"\"\n\n    REST_API_VERSION = \"api_x_v1/\"\n    USER_AUTH_TOKEN_ENDPOINT = \"auth_token/\"\n    FASTQ_UPLOAD_ENDPOINT = \"fq_file_upload/\"\n    FQ_DATASET_ENDPOINT = \"fq_dataset/\"\n    FQ_FILE_ENDPOINT = \"fq_file/\"\n    FQ_ATTACHMENT_ENDPOINT = \"fq_attachment/\"\n    PROJECT_ENDPOINT = \"project/\"\n    PROJECT_ATTACHMENT_ENDPOINT = \"project_attachment/\"\n    PRO_DATA_ENDPOINT = \"pro_data/\"\n\n    # Reserved Metadata Keys not allowed in metadata to \n    # avoid conflicts with ReadStore UI\n    METADATA_RESERVED_KEYS = ['id',\n                            'name',\n                            'project',\n                            'project_ids',\n                            'project_names',\n                            'owner_group_name',\n                            'qc_passed',\n                            'paired_end',\n                            'index_read',\n                            'created',\n                            'description',\n                            'owner_username',\n                            'fq_file_r1',\n                            'fq_file_r2',\n                            'fq_file_i1',\n                            'fq_file_i2',\n                            'id_project',\n                            'name_project',\n                            'name_og',\n                            'archived',\n                            'collaborators',\n                            'dataset_metadata_keys',\n                            'data_type',\n                            'version',\n                            'valid_to',\n                            'upload_path',\n                            'owner_username',\n                            'fq_dataset',\n                            'id_fq_dataset',\n                            'name_fq_dataset']\n\n    def __init__(\n        self, username: str, token: str, endpoint_url: str, output_format: str\n    ):\n        \"\"\"Constructor\n\n        Initialize a new RSClient object\n\n        Args:\n            username: ReadStore username\n            token: ReadStore user token\n            endpoint_url: The endpoint URL for the ReadStore API\n            output_format: The default output format for the client\n\n        Raises:\n            rsexceptions.ReadStoreError:\n                Server Connection to API Failed\n            rsexceptions.ReadStoreError:\n                User Authentication Failed\n        \"\"\"\n\n        self.username = username\n        self.token = token\n        self.endpoint = f\"{endpoint_url}/{self.REST_API_VERSION}\"\n        self.output_format = output_format\n        self.auth = HTTPBasicAuth(username, token)\n\n        if not self._test_server_connection():\n            raise rsexceptions.ReadStoreError(\n                f\"Server Connection Failed\\nEndpoint URL: {self.endpoint}\"\n            )\n\n        if not self._auth_user_token():\n            raise rsexceptions.ReadStoreError(\n                f\"User Authentication Failed\\nUsername: {self.username}\"\n            )\n\n    def _test_server_connection(self) -&gt; bool:\n        \"\"\"\n        Validate server URL\n\n        Returns:\n            True if server can be reached else False\n        \"\"\"\n\n        parsed_url = urlparse(self.endpoint)\n\n        if parsed_url.scheme not in [\"http\", \"https\"]:\n            return False\n        else:\n            try:\n                response = requests.head(self.endpoint)\n\n                if response.status_code == 200:\n                    return True\n                else:\n                    return False\n            except requests.exceptions.ConnectionError:\n                return False\n\n    def _auth_user_token(self) -&gt; bool:\n        \"\"\"\n        Validate user and token\n\n        Returns:\n            True if user token is valid else False\n        \"\"\"\n\n        try:\n            auth_endpoint = os.path.join(self.endpoint, self.USER_AUTH_TOKEN_ENDPOINT)\n\n            res = requests.post(auth_endpoint, auth=self.auth)\n\n            if res.status_code != 200:\n                return False\n            else:\n                return True\n\n        except requests.exceptions.ConnectionError:\n            return False\n\n\n    def validate_charset(self, query_str: str) -&gt; bool:\n        \"\"\"\n        Validate charset for query string\n\n        Args:\n            query_str (str): Query string to validate\n\n        Returns:\n            bool: \n        \"\"\"\n\n        allowed = string.digits + string.ascii_lowercase + string.ascii_uppercase + '_-.@'\n        allowed = set(allowed)\n\n        return set(query_str) &lt;= allowed\n\n    def validate_metadata(self, metadata: dict) -&gt; None:\n        \"\"\"\n        Validate metadata dict\n\n        Ensure keys are non-empty, valid charset and not reserved\n\n        Args:\n            metadata (dict): Metadata to validate\n\n        Raises:\n            rsexceptions.ReadStoreError: If key is invalid\n        \"\"\"\n\n        for key, value in metadata.items():\n            if key == '':\n                raise rsexceptions.ReadStoreError(\"Empty Key\")\n            if not self.validate_charset(key):\n                raise rsexceptions.ReadStoreError(\"Invalid character in key. Must be alphanumeric or _-.@\")\n            if key in self.METADATA_RESERVED_KEYS:\n                raise rsexceptions.ReadStoreError(f\"Reserved Keyword not allowed in metadata: {key}\")\n\n\n    def get_output_format(self) -&gt; str:\n        \"\"\"\n        Get Output Format set for client\n\n        Return:\n            str output format\n        \"\"\"\n\n        return self.output_format\n\n\n    def upload_fastq(self,\n                     fastq_path: str,\n                     fastq_name: str | None = None,\n                     read_type: str | None = None) -&gt; None:\n        \"\"\"Upload Fastq Files\n\n        Upload Fastq files to ReadStore.\n        Check if file exists and has read permissions.\n\n        fastq_name: List of Fastq names for files to upload\n        read_type: List of read types for files to upload\n\n        Args:\n            fastq_path: List of Fastq files to upload\n            fastq_name: List of Fastq names for files to upload\n            read_types: List of read types for files to upload\n            read_types: Must be in ['R1', 'R2', 'I1', 'I2']\n\n        Raises:\n            rsexceptions.ReadStoreError: If file not found\n            rsexceptions.ReadStoreError: If no read permissions\n            rsexceptions.ReadStoreError: If upload URL request failed\n        \"\"\"\n\n        fq_upload_endpoint = os.path.join(self.endpoint, self.FASTQ_UPLOAD_ENDPOINT)\n\n        # Run parallel uploads of fastq files\n        fastq_path = os.path.abspath(fastq_path)\n\n        # Make sure file exists and\n        if not os.path.exists(fastq_path):\n            raise rsexceptions.ReadStoreError(f\"File Not Found: {fastq_path}\")\n        elif not os.access(fastq_path, os.R_OK):\n            raise rsexceptions.ReadStoreError(f\"No read permissions: {fastq_path}\")\n\n        payload = {\n            \"fq_file_path\": fastq_path,\n        }\n\n        if not fastq_name is None:\n            if fastq_name == \"\":\n                raise rsexceptions.ReadStoreError(\"Fastq Name Is Empty\")\n            if not self.validate_charset(fastq_name):\n                raise rsexceptions.ReadStoreError(\"Invalid Fastq Name\")\n            payload[\"fq_file_name\"] = fastq_name\n\n        if not read_type is None:\n            if read_type not in [\"R1\", \"R2\", \"I1\", \"I2\"]:\n                raise rsexceptions.ReadStoreError(\"Invalid Read Type\")\n            payload[\"read_type\"] = read_type\n\n        res = requests.post(fq_upload_endpoint, json=payload, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            res_message = res.json().get(\"detail\", \"No Message\")\n            raise rsexceptions.ReadStoreError(\n                f\"Upload URL Request Failed: {res_message}\"\n            )\n\n    def get_fq_file(self, fq_file_id: int) -&gt; Dict:\n        \"\"\"Get Fastq File\n\n        Return Fastq file data by fq_file ID\n\n        Args:\n            fq_file_id: ID (pk) of fq_file\n\n        Returns:\n            dict with fq file data\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n        res = requests.get(fq_file_endpoint + f'{fq_file_id}/',auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"get_fq_file failed: {detail}\")\n        else:\n            return res.json()[0]\n\n\n    def list_fq_files(self) -&gt; List[Dict]:\n        \"\"\"List Fastq Files\n\n        List Fastq files in ReadStore\n\n        Returns:\n            List of Fastq files\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n        res = requests.get(fq_file_endpoint, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"list_fq_files failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def create_fq_file(self,\n                       name: str,\n                       read_type: str,\n                       qc_passed: bool,\n                       read_length: int,\n                       num_reads: int,\n                       size_mb: int,\n                       qc_phred_mean: float,\n                       qc_phred: dict,\n                       upload_path: str,\n                       md5_checksum: str,\n                       staging: bool,\n                       pipeline_version: str) -&gt; dict:\n        \"\"\"Create Fastq File\n\n        Create Fastq file in ReadStore\n\n        Args:\n            name: Fastq file name\n            read_type: Read type (R1, R2, I1, I2)\n            qc_passed: QC Pass\n            read_length: Read length\n            num_reads: Number of reads\n            size_mb: Size in MB\n            qc_phred_mean: QC Phred Mean\n            qc_phred: QC Phred\n            upload_path: Upload Path\n            md5_checksum: MD5 Checksum\n            staging: Staging\n            pipeline_version: Pipeline Version\n\n        Returns:    \n            dict: Fastq file data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n        # Define json for post request\n        json = {\n            \"name\": name,\n            \"read_type\": read_type,\n            \"qc_passed\": qc_passed,\n            \"read_length\": read_length,\n            \"num_reads\": num_reads,\n            \"size_mb\": size_mb,\n            \"qc_phred_mean\": qc_phred_mean,\n            \"qc_phred\": qc_phred,\n            \"upload_path\": upload_path,\n            \"md5_checksum\": md5_checksum,\n            \"staging\": staging,\n            \"pipeline_version\": pipeline_version\n        }\n\n        res = requests.post(fq_file_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 201:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"create_fq_file failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def update_fq_file(self,\n                       fq_file_id: int,\n                       name: str,\n                       read_type: str,\n                       qc_passed: bool,\n                       read_length: int,\n                       num_reads: int,\n                       size_mb: int,\n                       qc_phred_mean: float,\n                       qc_phred: dict,\n                       upload_path: str,\n                       md5_checksum: str,\n                       staging: bool,\n                       pipeline_version: str) -&gt; dict:\n\n        \"\"\"Update Fastq File\n\n        Update Fastq file in ReadStore\n\n        Args:\n            fq_file_id: ID of Fastq file\n            name: Fastq file name\n            read_type: Read type (R1, R2, I1, I2)\n            qc_passed: QC Pass\n            read_length: Read length\n            num_reads: Number of reads\n            size_mb: Size in MB\n            qc_phred_mean: QC Phred Mean\n            qc_phred: QC Phred\n            upload_path: Upload Path\n            md5_checksum: MD5 Checksum\n            staging: Staging\n            pipeline_version: Pipeline Version\n\n        Returns:    \n            dict: Fastq file data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT, f'{fq_file_id}/')\n\n        # Define json for post request\n        json = {\n            \"name\": name,\n            \"read_type\": read_type,\n            \"qc_passed\": qc_passed,\n            \"read_length\": read_length,\n            \"num_reads\": num_reads,\n            \"size_mb\": size_mb,\n            \"qc_phred_mean\": qc_phred_mean,\n            \"qc_phred\": qc_phred,\n            \"upload_path\": upload_path,\n            \"md5_checksum\": md5_checksum,\n            \"staging\": staging,\n            \"pipeline_version\": pipeline_version\n        }\n\n        res = requests.put(fq_file_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 200:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"update_fq_file failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def delete_fq_file(self, fq_file_id: int):\n        \"\"\"Delete Fastq File\n\n        Delete Fastq file in ReadStore\n\n        Args:\n            fq_file_id: ID of Fastq file\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT, f'{fq_file_id}/')\n\n        res = requests.delete(fq_file_endpoint, auth=self.auth)\n\n        if not res.status_code in [200, 204]:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"delete_fq_file failed: {detail}\")        \n\n\n    def get_fq_file_upload_path(self, fq_file_id: int) -&gt; str:\n        \"\"\"Get FASTQ file upload path\n\n        Get upload path for FASTQ file by fq_file ID\n\n        Args:\n            fq_file_id: ID (pk) of FASTQ file\n\n        Raises:\n            rsexceptions.ReadStoreError: If upload_path is not found\n\n        Returns:\n            str: Upload path\n        \"\"\"\n\n        fq_file = self.get_fq_file(fq_file_id)\n\n        if \"upload_path\" not in fq_file:\n            raise rsexceptions.ReadStoreError(\"upload_path Not Found in FqFile entry\")\n\n        upload_path = fq_file.get(\"upload_path\")\n\n        return upload_path\n\n\n    def list_fastq_datasets(\n        self,\n        project_name: str | None = None,\n        project_id: int | None = None,\n        role: str | None = None,\n    ) -&gt; List[dict]:\n        \"\"\"\n        List FASTQ Datasets\n\n        List FASTQ datasets and filter by project_name, project_id or role.\n        Role can be owner, collaborator or creator.\n\n        Args:\n            project_name: Filter fq_datasets by project name\n            project_id: Filter fq_datasets by project ID\n            role: Filter fq_datasets by owner role (owner, collaborator, creator)\n\n        Raises:\n            rsexceptions.ReadStoreError if role is not valid\n            rsexceptions.ReadStoreError request failed\n\n        Returns:\n            List[Dict]: FASTQ datasets in JSON format\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n        # Define json for post request\n        json = {}\n\n        if role:\n            if role.lower() in [\"owner\", \"collaborator\", \"creator\"]:\n                json[\"role\"] = role\n            else:\n                raise rsexceptions.ReadStoreError(\"Invalid Role\")\n\n        if project_name:\n            json[\"project_name\"] = project_name\n        if project_id:\n            json[\"project_id\"] = project_id\n\n        res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"list_fastq_datasets failed: {detail}\")\n        else:\n            return res.json()\n\n    def get_fastq_dataset(\n        self,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None\n    ) -&gt; Dict:\n        \"\"\"Get FASTQ dataset\n\n        Get FASTQ dataset by provided dataset_id or dataset_name\n        If dataset_name is not unique an error is printed\n\n        Args:\n            dataset_id: fq_dataset ID (or pk) to select\n            dataset_name: fq_dataset Name to select\n\n        Raises:\n            rsexceptions.ReadStoreError: If backend request failed\n            rsexceptions.ReadStoreError:\n                If multiple datasets found with same name.\n                This can occur if datasets with identical name were shared with you.\n\n        Returns:\n            Dict: Json Detail response\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n        if dataset_id is None and dataset_name is None: \n            raise rsexceptions.ReadStoreError(\"Dataset ID or Name Required\")\n\n        # Define json for post request\n        json = {}\n        if dataset_id:\n            json[\"id\"] = dataset_id\n        if dataset_name:\n            json[\"name\"] = dataset_name\n\n        res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n        # Remove entries not requested\n        if res.status_code not in [200, 204]:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"get_fastq_dataset failed: {detail}\")\n        else:\n            # If no dataset found, return empty dict\n            if len(res.json()) == 0:\n                return {}\n            # If several datasets found, return error\n            elif len(res.json()) &gt; 1:\n                raise rsexceptions.ReadStoreError(\n                    \"\"\"Multiple Datasets Found.\\n\n                    This can happen if datasets with identical name were\n                    shared with you.\\nUse dataset_id to get the correct dataset.\"\"\"\n                )\n            else:\n                return res.json()[0]\n\n    def create_fastq_dataset(self,\n                            name: str,\n                            description: str,\n                            qc_passed: bool,\n                            paired_end: bool,\n                            index_read: bool,\n                            project_ids: List[int],\n                            project_names: List[str],\n                            metadata: dict,\n                            fq_file_r1_id: int | None,\n                            fq_file_r2_id: int | None,\n                            fq_file_i1_id: int | None,\n                            fq_file_i2_id: int | None) -&gt; dict:\n        \"\"\"Create Fastq Dataset \n\n        Create Fastq dataset in ReadStore\n        Name must be non-empty and alphanumeric or _-.@\n\n        Metadata keys must be non-empty, valid charset and not reserved\n\n        Args:\n            name: Dataset name\n            description: Dataset description\n            qc_passed: QC Pass\n            paired_end: Paired End\n            index_read: Index Read\n            project_ids: List of project IDs\n            project_names: List of project names\n            metadata: Metadata\n            fq_file_r1_id: Fastq file R1 ID\n            fq_file_r2_id: Fastq file R2 ID\n            fq_file_i1_id: Fastq file I1 ID\n            fq_file_i2_id: Fastq file I2 ID\n\n        Returns:\n            dict: Created Fastq dataset\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n        if name == '':\n            raise rsexceptions.ReadStoreError(\"Empty Name\")\n        if not self.validate_charset(name):\n            raise rsexceptions.ReadStoreError(\"Invalid character in name. Must be alphanumeric or _-.@\")\n\n        self.validate_metadata(metadata)\n\n        # Define json for post request\n        json = {\n            \"name\": name,\n            \"description\": description,\n            \"qc_passed\": qc_passed,\n            \"paired_end\": paired_end,\n            \"index_read\": index_read,\n            \"project_ids\": project_ids,\n            \"project_names\": project_names,\n            \"metadata\": metadata,\n            \"fq_file_r1\": fq_file_r1_id,\n            \"fq_file_r2\": fq_file_r2_id,\n            \"fq_file_i1\": fq_file_i1_id,\n            \"fq_file_i2\": fq_file_i2_id\n        }\n\n        res = requests.post(fq_dataset_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 201:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"create_fastq_dataset failed: {detail}\")\n        else:\n            return res.json()\n\n    def update_fastq_dataset(self,\n                             dataset_id: int,\n                             name: str,\n                             description: str,\n                             qc_passed: bool,\n                             paired_end: bool,\n                             index_read: bool,\n                             project_ids: List[int],\n                             project_names: List[str],\n                             metadata: dict,\n                             fq_file_r1_id: int | None,\n                             fq_file_r2_id: int | None,\n                             fq_file_i1_id: int | None,\n                             fq_file_i2_id: int | None) -&gt; dict:\n        \"\"\"Update Fastq Dataset\n\n        Update Fastq dataset in ReadStore\n\n        Args:\n            dataset_id: ID of the dataset to update\n            name: Dataset name\n            description: Dataset description\n            qc_passed: QC Pass\n            paired_end: Paired End\n            index_read: Index Read\n            project_ids: List of project IDs\n            project_names: List of project names\n            metadata: Metadata\n            fq_file_r1_id: Fastq file R1 ID\n            fq_file_r2_id: Fastq file R2 ID\n            fq_file_i1_id: Fastq file I1 ID\n            fq_file_i2_id: Fastq file I2 ID\n\n        Returns:\n            dict: Updated Fastq dataset\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT, f'{dataset_id}/')\n\n        # Define json for put request\n        json = {\n            \"name\": name,\n            \"description\": description,\n            \"qc_passed\": qc_passed,\n            \"paired_end\": paired_end,\n            \"index_read\": index_read,\n            \"project_ids\": project_ids,\n            \"project_names\": project_names,\n            \"metadata\": metadata,\n            \"fq_file_r1\": fq_file_r1_id,\n            \"fq_file_r2\": fq_file_r2_id,\n            \"fq_file_i1\": fq_file_i1_id,\n            \"fq_file_i2\": fq_file_i2_id\n        }\n\n        res = requests.put(fq_dataset_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 200:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"update_fastq_dataset failed: {detail}\")\n        else:\n            return res.json()\n\n    def delete_fastq_dataset(self, dataset_id: int) -&gt; None:\n        \"\"\"Delete Fastq Dataset\n\n        Delete Fastq dataset in ReadStore\n\n        Args:\n            dataset_id: ID of Fastq dataset\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT, f'{dataset_id}/')\n\n        res = requests.delete(fq_dataset_endpoint, auth=self.auth)\n\n        if not res.status_code in [200,204]:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"delete_fastq_dataset failed: {detail}\")\n\n\n    def list_projects(self, role: str | None = None) -&gt; List[Dict]:\n        \"\"\"List Projects\n\n        List projects and optionally filter by role\n\n        Args:\n            role: Owner role to filter (owner, collaborator, creator)\n\n        Raises:\n            rsexceptions.ReadStoreError: If role is not valid\n            rsexceptions.ReadStoreError: If request failed\n\n        Returns:\n            List[Dict]: List of projects\n        \"\"\"\n\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n        # Define json for post request\n        json = {}\n        if role:\n            if role.lower() in [\"owner\", \"collaborator\", \"creator\"]:\n                json[\"role\"] = role\n            else:\n                raise rsexceptions.ReadStoreError(\"Invalid Role\")\n\n        res = requests.get(project_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"list_projects failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def get_project(\n        self,\n        project_id: int | None = None,\n        project_name: str | None = None\n    ) -&gt; Dict:\n        \"\"\"Get Individual Project\n\n        Return project details by project_id or project_name\n        If name is duplicated, print error message\n\n        Args:\n            project_id: Project ID\n            project_name: Project Name\n\n        Raise\n            rsexceptions.ReadStoreError: If request failed\n            rsexceptions.ReadStoreError: If duplicate names are found\n\n        Returns:\n            project detail response\n        \"\"\"\n\n        assert project_id or project_name, \"project_id or project_name Required\"\n\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n        # Define json for post request\n        json = {\"username\": self.username, \"token\": self.token}\n\n        if project_id:\n            json[\"id\"] = project_id\n        if project_name:\n            json[\"name\"] = project_name\n\n        res = requests.get(project_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"get_project failed: {detail}\")\n        else:\n            if len(res.json()) == 0:\n                return {}\n            # If several datasets found, return error\n            elif len(res.json()) &gt; 1:\n                raise rsexceptions.ReadStoreError(\n                    \"\"\"Multiple Projects Found.\\n\n                This can happen if Projects with identical name were shared with you.\\n\n                Use unique Project ID to access the correct dataset.\"\"\"\n                )\n            else:\n                return res.json()[0]\n\n    def create_project(self,\n                       name: str,\n                       description: str,\n                       metadata: dict,\n                       dataset_metadata_keys: List[str]) -&gt; dict:\n        \"\"\"Create Project\n\n        Create a new project in ReadStore\n\n        Name must be non-empty and alphanumeric or _-.@\n\n        Metadata dict keys must be non-empty, valid charset and not reserved\n\n        dataset_metadata_keys must be non-empty, valid charset and not reserved\n\n        Args:\n            name: Project name\n            description: Project description\n            metadata: Project metadata\n            dataset_metadata_keys: Dataset metadata keys\n\n        Returns:\n            dict: Created project data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n        dataset_metadata_keys = {key: \"\" for key in dataset_metadata_keys}\n\n        if name == '':\n            raise rsexceptions.ReadStoreError(\"Empty Name\")\n        if not self.validate_charset(name):\n            raise rsexceptions.ReadStoreError(\"Invalid character in name. Must be alphanumeric or _-.@\")\n\n        self.validate_metadata(metadata)\n\n        self.validate_metadata(dataset_metadata_keys)\n\n        json = {\n            \"name\": name,\n            \"description\": description,\n            \"metadata\": metadata,\n            \"dataset_metadata_keys\": dataset_metadata_keys\n        }\n\n        res = requests.post(project_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 201:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"create_project failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def update_project(self,\n                       project_id: int,\n                       name: str,\n                       description: str,\n                       metadata: dict,\n                       dataset_metadata_keys: List[str]) -&gt; dict:        \n        \"\"\"Update Project\n\n        Update an existing project in ReadStore\n\n        Args:\n            project_id: ID of the project to update\n            name: Project name\n            description: Project description\n            metadata: Project metadata\n            dataset_metadata_keys: Dataset metadata keys\n\n        Returns:\n            dict: Updated project data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT, f'{project_id}/')\n\n        dataset_metadata_keys = {key: \"\" for key in dataset_metadata_keys}\n\n        json = {\n            \"name\": name,\n            \"description\": description,\n            \"metadata\": metadata,\n            \"dataset_metadata_keys\": dataset_metadata_keys\n        }\n\n        res = requests.put(project_endpoint, json=json, auth=self.auth)\n\n        if res.status_code != 200:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"update_project failed: {detail}\")\n        else:\n            return res.json()\n\n\n    def delete_project(self, project_id: int) -&gt; None:\n        \"\"\"Delete Project\n\n        Delete a project in ReadStore\n\n        Args:\n            project_id: ID of the project to delete\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n        \"\"\"\n\n        project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT, f'{project_id}/')\n\n        res = requests.delete(project_endpoint, auth=self.auth)\n\n        if not res.status_code in [200,204]:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"delete_project failed: {detail}\")\n\n\n    def download_project_attachment(\n        self,\n        attachment_name: str,\n        outpath: str,\n        project_id: int | None = None,\n        project_name: str | None = None,\n    ):\n        \"\"\"Download Project Attachments\n\n        Download Project Attachment Files to local path\n\n        Args:\n            attachment_name: Attachment name\n            outpath: Path to write to\n            project_id: Id of project\n            project_name: Project name.\n\n        Raises:\n            rsexceptions.ReadStoreError: Request failed\n            rsexceptions.ReadStoreError: Attachment not Found\n            rsexceptions.ReadStoreError: Multiple Attachments Found for Project.\n        \"\"\"\n\n        project_attachment_endpoint = os.path.join(\n            self.endpoint, self.PROJECT_ATTACHMENT_ENDPOINT\n        )\n\n        assert project_id or project_name, \\\n            \"Either project_id or project_name required\"\n\n        # Define json for post request\n        json = {\n            \"attachment_name\": attachment_name\n        }\n\n        if project_id:\n            json[\"project_id\"] = project_id\n        if project_name:\n            json[\"project_name\"] = project_name\n\n        res = requests.get(project_attachment_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"download_project_attachment failed: {detail}\")\n        elif len(res.json()) == 0:\n            raise rsexceptions.ReadStoreError(\"Attachment Not Found\")\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Attachments Found For Project.\n                This can happen if Projects with identical name were shared with you.\\n\n                Use unique Project ID to access the correct attachment.\"\"\"\n            )\n        else:\n            attachment = res.json()[0]\n            with open(outpath, \"wb\") as fh:\n                fh.write(base64.b64decode(attachment[\"body\"]))\n\n\n    def download_fq_dataset_attachment(\n        self,\n        attachment_name: str,\n        outpath: str,\n        dataset_id: int | None = None,\n        dataset_name: str | None = None,\n    ):\n        \"\"\"Fastq Attachments\n\n        Download Fastq Attachments\n\n        Args:\n            attachment_name: Attachment name\n            outpath: Path to write to\n            dataset_id: Id of project\n            dataset_name: Project name.\n\n        Raises:\n            rsexceptions.ReadStoreError: Request failed\n            rsexceptions.ReadStoreError: Attachment not Found\n            rsexceptions.ReadStoreError: Multiple Attachments Found for Project.\n        \"\"\"\n\n        fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_ATTACHMENT_ENDPOINT)\n\n        assert dataset_id or dataset_name, \"dataset_id or dataset_name required\"\n\n        # Define json for post request\n        json = {\n            \"attachment_name\": attachment_name,\n        }\n\n        if dataset_id:\n            json[\"dataset_id\"] = dataset_id\n        if dataset_name:\n            json[\"dataset_name\"] = dataset_name\n\n        res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:            \n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"download_fq_dataset_attachment failed {detail}\")\n        elif len(res.json()) == 0:\n            raise rsexceptions.ReadStoreError(\"Attachment Not Found\")\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Attachments Found For Dataset.\n                This can happen if Datasets with identical name were shared with you.\\n\n                Use unique Dataset ID to access the correct attachment.\"\"\"\n            )\n        else:\n            attachment = res.json()[0]\n            with open(outpath, \"wb\") as fh:\n                fh.write(base64.b64decode(attachment[\"body\"]))\n\n    def upload_pro_data(self,\n                        name: str,\n                        pro_data_path: str,\n                        data_type: str,\n                        dataset_id: int | None = None,\n                        dataset_name: str | None = None,\n                        metadata: dict = {},\n                        description: str = \"\") -&gt; None:\n        \"\"\"Upload Processed Data\n\n        Upload Pro Data to ReadStore\n\n        Args:\n            pro_data: Pro Data in JSON format\n\n        Raises:\n            rsexceptions.ReadStoreError: If upload request failed\n        \"\"\"\n\n        pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n        if name == '':\n            raise rsexceptions.ReadStoreError(\"Empty Name\")\n        if data_type == '':\n            raise rsexceptions.ReadStoreError(\"Empty Data Type\")\n        if not self.validate_charset(name):\n            raise rsexceptions.ReadStoreError(\"Invalid character in name. Must be alphanumeric or _-.@\")\n        if not self.validate_charset(data_type):\n            raise rsexceptions.ReadStoreError(\"Invalid character in data_type. Must be alphanumeric or _-.@\")\n\n        self.validate_metadata(metadata)\n\n        # Run parallel uploads of fastq files\n        pro_data_path = os.path.abspath(pro_data_path)\n\n        # Make sure file exists and\n        if not os.path.exists(pro_data_path):\n            raise rsexceptions.ReadStoreError(f\"File Not Found: {pro_data_path}\")\n        elif not os.access(pro_data_path, os.R_OK):\n            raise rsexceptions.ReadStoreError(f\"No read permissions: {pro_data_path}\")\n\n        # Define json for post request\n        json = {\n            \"name\" : name,\n            \"data_type\": data_type,\n            \"upload_path\": pro_data_path,\n            \"metadata\": metadata,\n            \"description\" : description,\n        }\n\n        if dataset_id:\n            json['dataset_id'] = dataset_id\n        if dataset_name:\n            json['dataset_name'] = dataset_name        \n\n        res = requests.post(pro_data_endpoint, json=json, auth=self.auth)\n\n        if res.status_code == 403:\n            raise rsexceptions.ReadStoreError(f\"Upload ProData Failed: {res.json().get('detail')}\")\n        elif res.status_code not in [201, 204]:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"upload_pro_data failed: {detail}\")\n\n\n    def list_pro_data(self,\n                      project_id: int | None = None,\n                      project_name: str | None = None,\n                      dataset_id: int | None = None,\n                      dataset_name: str | None = None,\n                      name: str | None = None,\n                      data_type: str | None = None,\n                      include_archived: bool = False) -&gt; List[Dict]:\n        \"\"\"List Processed Data\n\n        List Pro Data. Subset by arguments.\n\n        Args:\n            project_id: Project ID\n            project_name: Project Name\n            dataset_id: Dataset ID\n            dataset_name: Dataset Name\n            name: Pro Data Name\n            data_type: Data Type\n            include_archived: Include Archived Pro Data\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n\n        Returns:\n            List[Dict]: List of Pro Data\n        \"\"\"\n\n        pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n        # Define json for post request\n        json = {\n            'project_id': project_id,\n            'project_name': project_name,\n            'dataset_id': dataset_id,\n            'dataset_name': dataset_name,\n            'name': name,\n            'data_type': data_type\n        }\n\n        if not include_archived:\n            json['valid'] = True\n\n        res = requests.get(pro_data_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"list_pro_data failed {detail}\")\n        else:\n            return res.json()\n\n\n    def get_pro_data(self,\n                    pro_data_id: int | None = None,\n                    name: str | None = None,\n                    version: int | None = None,\n                    dataset_id: int | None = None,\n                    dataset_name: str | None = None) -&gt; Dict:   \n        \"\"\"Get Processed Data\n\n        Get Pro Data for Dataset\n\n        Provide pro_data_id or name plus dataset_id or dataset_name to query\n\n        Args:\n            pro_data_id: Dataset ID\n            name: Pro Data Name\n            version: Pro Data Version\n            dataset_id: Dataset ID\n            dataset_name: Dataset Name\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n\n        Returns:\n            Dict: Pro Data object\n        \"\"\"\n\n        if not pro_data_id:\n            assert name and (dataset_id or dataset_name), \"name and dataset_id or dataset_name required\"\n\n        pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n        if not version:\n            valid = 'true'\n        else:\n            valid = 'false'\n\n        # Define json for post request\n        json = {\n            'dataset_id': dataset_id,\n            'dataset_name': dataset_name,\n            'name': name,\n            'version': version,\n            'valid': valid,\n            'detail': 'true'\n        }\n\n        if pro_data_id:\n            res = requests.get(pro_data_endpoint + f'{pro_data_id}/', auth=self.auth)\n        else:\n            res = requests.get(pro_data_endpoint, params=json, auth=self.auth)\n\n        if res.status_code not in [200, 204]:\n\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n\n            raise rsexceptions.ReadStoreError(f\"list_pro_data failed {detail}\")\n        else:\n            if len(res.json()) == 0:\n                return {}\n            # If several datasets found, return error\n            elif len(res.json()) &gt; 1:\n                raise rsexceptions.ReadStoreError(\n                    \"\"\"Multiple Projects Found.\\n\n                This can happen if Projects with identical name were shared with you.\\n\n                Use unique Project ID to access the correct dataset.\"\"\"\n                )\n            else:\n                return res.json()[0]\n\n\n    def delete_pro_data(self,\n                        pro_data_id: int | None = None,\n                        name: str | None = None,\n                        dataset_id: int | None = None,\n                        dataset_name: str | None = None,\n                        version: int | None = None) -&gt; int:   \n        \"\"\"Delete Processed Data\n\n        Delete Pro Data for Dataset\n\n        Provide pro_data_id or name plus dataset_id or dataset_name to query\n\n        Args:\n            pro_data_id: Dataset ID\n            name: Pro Data Name\n            dataset_id: Dataset ID\n            dataset_name: Dataset Name\n            version: Pro Data Version\n\n        Raises:\n            rsexceptions.ReadStoreError: If request failed\n\n        Returns:\n            int: Pro Data ID\n        \"\"\"\n\n        if not pro_data_id:\n            assert name and (dataset_id or dataset_name), \"name and dataset_id or dataset_name required\"\n\n        pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n        # Define json for post request\n        json = {\n            'dataset_id': dataset_id,\n            'dataset_name': dataset_name,\n            'name': name,\n            'version': version,\n        }\n\n        if pro_data_id:\n            res = requests.delete(pro_data_endpoint + f'{pro_data_id}/', auth=self.auth)\n        else:\n            res = requests.delete(pro_data_endpoint, params=json, auth=self.auth)\n\n        if res.status_code == 400:\n            detail = res.json().get('detail', 'No Message')\n            if detail == 'ProData not found':\n                raise rsexceptions.ReadStoreError(\"ProData not found\")\n            else:\n                raise rsexceptions.ReadStoreError(\"delete_pro_data failed\")\n        elif res.status_code == 403:\n            raise rsexceptions.ReadStoreError(f\"ProData Delete Failed: {res.json().get('detail')}\")\n        elif res.status_code in [200, 204]:\n            return res.json().get('id')\n        else:\n            try:\n                detail = res.json()\n            except JSONDecodeError:\n                detail = \"No Message\"\n            raise rsexceptions.ReadStoreError(f\"delete_pro_data failed {detail}\")\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.__init__","title":"<code>__init__(username, token, endpoint_url, output_format)</code>","text":"<p>Constructor</p> <p>Initialize a new RSClient object</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>str</code> <p>ReadStore username</p> required <code>token</code> <code>str</code> <p>ReadStore user token</p> required <code>endpoint_url</code> <code>str</code> <p>The endpoint URL for the ReadStore API</p> required <code>output_format</code> <code>str</code> <p>The default output format for the client</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Server Connection to API Failed</p> <code>ReadStoreError</code> <p>User Authentication Failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def __init__(\n    self, username: str, token: str, endpoint_url: str, output_format: str\n):\n    \"\"\"Constructor\n\n    Initialize a new RSClient object\n\n    Args:\n        username: ReadStore username\n        token: ReadStore user token\n        endpoint_url: The endpoint URL for the ReadStore API\n        output_format: The default output format for the client\n\n    Raises:\n        rsexceptions.ReadStoreError:\n            Server Connection to API Failed\n        rsexceptions.ReadStoreError:\n            User Authentication Failed\n    \"\"\"\n\n    self.username = username\n    self.token = token\n    self.endpoint = f\"{endpoint_url}/{self.REST_API_VERSION}\"\n    self.output_format = output_format\n    self.auth = HTTPBasicAuth(username, token)\n\n    if not self._test_server_connection():\n        raise rsexceptions.ReadStoreError(\n            f\"Server Connection Failed\\nEndpoint URL: {self.endpoint}\"\n        )\n\n    if not self._auth_user_token():\n        raise rsexceptions.ReadStoreError(\n            f\"User Authentication Failed\\nUsername: {self.username}\"\n        )\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient._auth_user_token","title":"<code>_auth_user_token()</code>","text":"<p>Validate user and token</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if user token is valid else False</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def _auth_user_token(self) -&gt; bool:\n    \"\"\"\n    Validate user and token\n\n    Returns:\n        True if user token is valid else False\n    \"\"\"\n\n    try:\n        auth_endpoint = os.path.join(self.endpoint, self.USER_AUTH_TOKEN_ENDPOINT)\n\n        res = requests.post(auth_endpoint, auth=self.auth)\n\n        if res.status_code != 200:\n            return False\n        else:\n            return True\n\n    except requests.exceptions.ConnectionError:\n        return False\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient._test_server_connection","title":"<code>_test_server_connection()</code>","text":"<p>Validate server URL</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if server can be reached else False</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def _test_server_connection(self) -&gt; bool:\n    \"\"\"\n    Validate server URL\n\n    Returns:\n        True if server can be reached else False\n    \"\"\"\n\n    parsed_url = urlparse(self.endpoint)\n\n    if parsed_url.scheme not in [\"http\", \"https\"]:\n        return False\n    else:\n        try:\n            response = requests.head(self.endpoint)\n\n            if response.status_code == 200:\n                return True\n            else:\n                return False\n        except requests.exceptions.ConnectionError:\n            return False\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.create_fastq_dataset","title":"<code>create_fastq_dataset(name, description, qc_passed, paired_end, index_read, project_ids, project_names, metadata, fq_file_r1_id, fq_file_r2_id, fq_file_i1_id, fq_file_i2_id)</code>","text":"<p>Create Fastq Dataset </p> <p>Create Fastq dataset in ReadStore Name must be non-empty and alphanumeric or _-.@</p> <p>Metadata keys must be non-empty, valid charset and not reserved</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>qc_passed</code> <code>bool</code> <p>QC Pass</p> required <code>paired_end</code> <code>bool</code> <p>Paired End</p> required <code>index_read</code> <code>bool</code> <p>Index Read</p> required <code>project_ids</code> <code>List[int]</code> <p>List of project IDs</p> required <code>project_names</code> <code>List[str]</code> <p>List of project names</p> required <code>metadata</code> <code>dict</code> <p>Metadata</p> required <code>fq_file_r1_id</code> <code>int | None</code> <p>Fastq file R1 ID</p> required <code>fq_file_r2_id</code> <code>int | None</code> <p>Fastq file R2 ID</p> required <code>fq_file_i1_id</code> <code>int | None</code> <p>Fastq file I1 ID</p> required <code>fq_file_i2_id</code> <code>int | None</code> <p>Fastq file I2 ID</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Created Fastq dataset</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def create_fastq_dataset(self,\n                        name: str,\n                        description: str,\n                        qc_passed: bool,\n                        paired_end: bool,\n                        index_read: bool,\n                        project_ids: List[int],\n                        project_names: List[str],\n                        metadata: dict,\n                        fq_file_r1_id: int | None,\n                        fq_file_r2_id: int | None,\n                        fq_file_i1_id: int | None,\n                        fq_file_i2_id: int | None) -&gt; dict:\n    \"\"\"Create Fastq Dataset \n\n    Create Fastq dataset in ReadStore\n    Name must be non-empty and alphanumeric or _-.@\n\n    Metadata keys must be non-empty, valid charset and not reserved\n\n    Args:\n        name: Dataset name\n        description: Dataset description\n        qc_passed: QC Pass\n        paired_end: Paired End\n        index_read: Index Read\n        project_ids: List of project IDs\n        project_names: List of project names\n        metadata: Metadata\n        fq_file_r1_id: Fastq file R1 ID\n        fq_file_r2_id: Fastq file R2 ID\n        fq_file_i1_id: Fastq file I1 ID\n        fq_file_i2_id: Fastq file I2 ID\n\n    Returns:\n        dict: Created Fastq dataset\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n    if name == '':\n        raise rsexceptions.ReadStoreError(\"Empty Name\")\n    if not self.validate_charset(name):\n        raise rsexceptions.ReadStoreError(\"Invalid character in name. Must be alphanumeric or _-.@\")\n\n    self.validate_metadata(metadata)\n\n    # Define json for post request\n    json = {\n        \"name\": name,\n        \"description\": description,\n        \"qc_passed\": qc_passed,\n        \"paired_end\": paired_end,\n        \"index_read\": index_read,\n        \"project_ids\": project_ids,\n        \"project_names\": project_names,\n        \"metadata\": metadata,\n        \"fq_file_r1\": fq_file_r1_id,\n        \"fq_file_r2\": fq_file_r2_id,\n        \"fq_file_i1\": fq_file_i1_id,\n        \"fq_file_i2\": fq_file_i2_id\n    }\n\n    res = requests.post(fq_dataset_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 201:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"create_fastq_dataset failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.create_fq_file","title":"<code>create_fq_file(name, read_type, qc_passed, read_length, num_reads, size_mb, qc_phred_mean, qc_phred, upload_path, md5_checksum, staging, pipeline_version)</code>","text":"<p>Create Fastq File</p> <p>Create Fastq file in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Fastq file name</p> required <code>read_type</code> <code>str</code> <p>Read type (R1, R2, I1, I2)</p> required <code>qc_passed</code> <code>bool</code> <p>QC Pass</p> required <code>read_length</code> <code>int</code> <p>Read length</p> required <code>num_reads</code> <code>int</code> <p>Number of reads</p> required <code>size_mb</code> <code>int</code> <p>Size in MB</p> required <code>qc_phred_mean</code> <code>float</code> <p>QC Phred Mean</p> required <code>qc_phred</code> <code>dict</code> <p>QC Phred</p> required <code>upload_path</code> <code>str</code> <p>Upload Path</p> required <code>md5_checksum</code> <code>str</code> <p>MD5 Checksum</p> required <code>staging</code> <code>bool</code> <p>Staging</p> required <code>pipeline_version</code> <code>str</code> <p>Pipeline Version</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Fastq file data</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def create_fq_file(self,\n                   name: str,\n                   read_type: str,\n                   qc_passed: bool,\n                   read_length: int,\n                   num_reads: int,\n                   size_mb: int,\n                   qc_phred_mean: float,\n                   qc_phred: dict,\n                   upload_path: str,\n                   md5_checksum: str,\n                   staging: bool,\n                   pipeline_version: str) -&gt; dict:\n    \"\"\"Create Fastq File\n\n    Create Fastq file in ReadStore\n\n    Args:\n        name: Fastq file name\n        read_type: Read type (R1, R2, I1, I2)\n        qc_passed: QC Pass\n        read_length: Read length\n        num_reads: Number of reads\n        size_mb: Size in MB\n        qc_phred_mean: QC Phred Mean\n        qc_phred: QC Phred\n        upload_path: Upload Path\n        md5_checksum: MD5 Checksum\n        staging: Staging\n        pipeline_version: Pipeline Version\n\n    Returns:    \n        dict: Fastq file data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n    # Define json for post request\n    json = {\n        \"name\": name,\n        \"read_type\": read_type,\n        \"qc_passed\": qc_passed,\n        \"read_length\": read_length,\n        \"num_reads\": num_reads,\n        \"size_mb\": size_mb,\n        \"qc_phred_mean\": qc_phred_mean,\n        \"qc_phred\": qc_phred,\n        \"upload_path\": upload_path,\n        \"md5_checksum\": md5_checksum,\n        \"staging\": staging,\n        \"pipeline_version\": pipeline_version\n    }\n\n    res = requests.post(fq_file_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 201:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"create_fq_file failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.create_project","title":"<code>create_project(name, description, metadata, dataset_metadata_keys)</code>","text":"<p>Create Project</p> <p>Create a new project in ReadStore</p> <p>Name must be non-empty and alphanumeric or _-.@</p> <p>Metadata dict keys must be non-empty, valid charset and not reserved</p> <p>dataset_metadata_keys must be non-empty, valid charset and not reserved</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Project name</p> required <code>description</code> <code>str</code> <p>Project description</p> required <code>metadata</code> <code>dict</code> <p>Project metadata</p> required <code>dataset_metadata_keys</code> <code>List[str]</code> <p>Dataset metadata keys</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Created project data</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def create_project(self,\n                   name: str,\n                   description: str,\n                   metadata: dict,\n                   dataset_metadata_keys: List[str]) -&gt; dict:\n    \"\"\"Create Project\n\n    Create a new project in ReadStore\n\n    Name must be non-empty and alphanumeric or _-.@\n\n    Metadata dict keys must be non-empty, valid charset and not reserved\n\n    dataset_metadata_keys must be non-empty, valid charset and not reserved\n\n    Args:\n        name: Project name\n        description: Project description\n        metadata: Project metadata\n        dataset_metadata_keys: Dataset metadata keys\n\n    Returns:\n        dict: Created project data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n    dataset_metadata_keys = {key: \"\" for key in dataset_metadata_keys}\n\n    if name == '':\n        raise rsexceptions.ReadStoreError(\"Empty Name\")\n    if not self.validate_charset(name):\n        raise rsexceptions.ReadStoreError(\"Invalid character in name. Must be alphanumeric or _-.@\")\n\n    self.validate_metadata(metadata)\n\n    self.validate_metadata(dataset_metadata_keys)\n\n    json = {\n        \"name\": name,\n        \"description\": description,\n        \"metadata\": metadata,\n        \"dataset_metadata_keys\": dataset_metadata_keys\n    }\n\n    res = requests.post(project_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 201:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"create_project failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.delete_fastq_dataset","title":"<code>delete_fastq_dataset(dataset_id)</code>","text":"<p>Delete Fastq Dataset</p> <p>Delete Fastq dataset in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int</code> <p>ID of Fastq dataset</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def delete_fastq_dataset(self, dataset_id: int) -&gt; None:\n    \"\"\"Delete Fastq Dataset\n\n    Delete Fastq dataset in ReadStore\n\n    Args:\n        dataset_id: ID of Fastq dataset\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT, f'{dataset_id}/')\n\n    res = requests.delete(fq_dataset_endpoint, auth=self.auth)\n\n    if not res.status_code in [200,204]:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"delete_fastq_dataset failed: {detail}\")\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.delete_fq_file","title":"<code>delete_fq_file(fq_file_id)</code>","text":"<p>Delete Fastq File</p> <p>Delete Fastq file in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_id</code> <code>int</code> <p>ID of Fastq file</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def delete_fq_file(self, fq_file_id: int):\n    \"\"\"Delete Fastq File\n\n    Delete Fastq file in ReadStore\n\n    Args:\n        fq_file_id: ID of Fastq file\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT, f'{fq_file_id}/')\n\n    res = requests.delete(fq_file_endpoint, auth=self.auth)\n\n    if not res.status_code in [200, 204]:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"delete_fq_file failed: {detail}\")        \n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.delete_pro_data","title":"<code>delete_pro_data(pro_data_id=None, name=None, dataset_id=None, dataset_name=None, version=None)</code>","text":"<p>Delete Processed Data</p> <p>Delete Pro Data for Dataset</p> <p>Provide pro_data_id or name plus dataset_id or dataset_name to query</p> <p>Parameters:</p> Name Type Description Default <code>pro_data_id</code> <code>int | None</code> <p>Dataset ID</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Pro Data Name</p> <code>None</code> <code>dataset_id</code> <code>int | None</code> <p>Dataset ID</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Dataset Name</p> <code>None</code> <code>version</code> <code>int | None</code> <p>Pro Data Version</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Pro Data ID</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def delete_pro_data(self,\n                    pro_data_id: int | None = None,\n                    name: str | None = None,\n                    dataset_id: int | None = None,\n                    dataset_name: str | None = None,\n                    version: int | None = None) -&gt; int:   \n    \"\"\"Delete Processed Data\n\n    Delete Pro Data for Dataset\n\n    Provide pro_data_id or name plus dataset_id or dataset_name to query\n\n    Args:\n        pro_data_id: Dataset ID\n        name: Pro Data Name\n        dataset_id: Dataset ID\n        dataset_name: Dataset Name\n        version: Pro Data Version\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n\n    Returns:\n        int: Pro Data ID\n    \"\"\"\n\n    if not pro_data_id:\n        assert name and (dataset_id or dataset_name), \"name and dataset_id or dataset_name required\"\n\n    pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n    # Define json for post request\n    json = {\n        'dataset_id': dataset_id,\n        'dataset_name': dataset_name,\n        'name': name,\n        'version': version,\n    }\n\n    if pro_data_id:\n        res = requests.delete(pro_data_endpoint + f'{pro_data_id}/', auth=self.auth)\n    else:\n        res = requests.delete(pro_data_endpoint, params=json, auth=self.auth)\n\n    if res.status_code == 400:\n        detail = res.json().get('detail', 'No Message')\n        if detail == 'ProData not found':\n            raise rsexceptions.ReadStoreError(\"ProData not found\")\n        else:\n            raise rsexceptions.ReadStoreError(\"delete_pro_data failed\")\n    elif res.status_code == 403:\n        raise rsexceptions.ReadStoreError(f\"ProData Delete Failed: {res.json().get('detail')}\")\n    elif res.status_code in [200, 204]:\n        return res.json().get('id')\n    else:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n        raise rsexceptions.ReadStoreError(f\"delete_pro_data failed {detail}\")\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.delete_project","title":"<code>delete_project(project_id)</code>","text":"<p>Delete Project</p> <p>Delete a project in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int</code> <p>ID of the project to delete</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def delete_project(self, project_id: int) -&gt; None:\n    \"\"\"Delete Project\n\n    Delete a project in ReadStore\n\n    Args:\n        project_id: ID of the project to delete\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT, f'{project_id}/')\n\n    res = requests.delete(project_endpoint, auth=self.auth)\n\n    if not res.status_code in [200,204]:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"delete_project failed: {detail}\")\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.download_fq_dataset_attachment","title":"<code>download_fq_dataset_attachment(attachment_name, outpath, dataset_id=None, dataset_name=None)</code>","text":"<p>Fastq Attachments</p> <p>Download Fastq Attachments</p> <p>Parameters:</p> Name Type Description Default <code>attachment_name</code> <code>str</code> <p>Attachment name</p> required <code>outpath</code> <code>str</code> <p>Path to write to</p> required <code>dataset_id</code> <code>int | None</code> <p>Id of project</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Project name.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Request failed</p> <code>ReadStoreError</code> <p>Attachment not Found</p> <code>ReadStoreError</code> <p>Multiple Attachments Found for Project.</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def download_fq_dataset_attachment(\n    self,\n    attachment_name: str,\n    outpath: str,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None,\n):\n    \"\"\"Fastq Attachments\n\n    Download Fastq Attachments\n\n    Args:\n        attachment_name: Attachment name\n        outpath: Path to write to\n        dataset_id: Id of project\n        dataset_name: Project name.\n\n    Raises:\n        rsexceptions.ReadStoreError: Request failed\n        rsexceptions.ReadStoreError: Attachment not Found\n        rsexceptions.ReadStoreError: Multiple Attachments Found for Project.\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_ATTACHMENT_ENDPOINT)\n\n    assert dataset_id or dataset_name, \"dataset_id or dataset_name required\"\n\n    # Define json for post request\n    json = {\n        \"attachment_name\": attachment_name,\n    }\n\n    if dataset_id:\n        json[\"dataset_id\"] = dataset_id\n    if dataset_name:\n        json[\"dataset_name\"] = dataset_name\n\n    res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:            \n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"download_fq_dataset_attachment failed {detail}\")\n    elif len(res.json()) == 0:\n        raise rsexceptions.ReadStoreError(\"Attachment Not Found\")\n    elif len(res.json()) &gt; 1:\n        raise rsexceptions.ReadStoreError(\n            \"\"\"Multiple Attachments Found For Dataset.\n            This can happen if Datasets with identical name were shared with you.\\n\n            Use unique Dataset ID to access the correct attachment.\"\"\"\n        )\n    else:\n        attachment = res.json()[0]\n        with open(outpath, \"wb\") as fh:\n            fh.write(base64.b64decode(attachment[\"body\"]))\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.download_project_attachment","title":"<code>download_project_attachment(attachment_name, outpath, project_id=None, project_name=None)</code>","text":"<p>Download Project Attachments</p> <p>Download Project Attachment Files to local path</p> <p>Parameters:</p> Name Type Description Default <code>attachment_name</code> <code>str</code> <p>Attachment name</p> required <code>outpath</code> <code>str</code> <p>Path to write to</p> required <code>project_id</code> <code>int | None</code> <p>Id of project</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Project name.</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>Request failed</p> <code>ReadStoreError</code> <p>Attachment not Found</p> <code>ReadStoreError</code> <p>Multiple Attachments Found for Project.</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def download_project_attachment(\n    self,\n    attachment_name: str,\n    outpath: str,\n    project_id: int | None = None,\n    project_name: str | None = None,\n):\n    \"\"\"Download Project Attachments\n\n    Download Project Attachment Files to local path\n\n    Args:\n        attachment_name: Attachment name\n        outpath: Path to write to\n        project_id: Id of project\n        project_name: Project name.\n\n    Raises:\n        rsexceptions.ReadStoreError: Request failed\n        rsexceptions.ReadStoreError: Attachment not Found\n        rsexceptions.ReadStoreError: Multiple Attachments Found for Project.\n    \"\"\"\n\n    project_attachment_endpoint = os.path.join(\n        self.endpoint, self.PROJECT_ATTACHMENT_ENDPOINT\n    )\n\n    assert project_id or project_name, \\\n        \"Either project_id or project_name required\"\n\n    # Define json for post request\n    json = {\n        \"attachment_name\": attachment_name\n    }\n\n    if project_id:\n        json[\"project_id\"] = project_id\n    if project_name:\n        json[\"project_name\"] = project_name\n\n    res = requests.get(project_attachment_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"download_project_attachment failed: {detail}\")\n    elif len(res.json()) == 0:\n        raise rsexceptions.ReadStoreError(\"Attachment Not Found\")\n    elif len(res.json()) &gt; 1:\n        raise rsexceptions.ReadStoreError(\n            \"\"\"Multiple Attachments Found For Project.\n            This can happen if Projects with identical name were shared with you.\\n\n            Use unique Project ID to access the correct attachment.\"\"\"\n        )\n    else:\n        attachment = res.json()[0]\n        with open(outpath, \"wb\") as fh:\n            fh.write(base64.b64decode(attachment[\"body\"]))\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.get_fastq_dataset","title":"<code>get_fastq_dataset(dataset_id=None, dataset_name=None)</code>","text":"<p>Get FASTQ dataset</p> <p>Get FASTQ dataset by provided dataset_id or dataset_name If dataset_name is not unique an error is printed</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int | None</code> <p>fq_dataset ID (or pk) to select</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>fq_dataset Name to select</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If backend request failed</p> <code>ReadStoreError</code> <p>If multiple datasets found with same name. This can occur if datasets with identical name were shared with you.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Json Detail response</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def get_fastq_dataset(\n    self,\n    dataset_id: int | None = None,\n    dataset_name: str | None = None\n) -&gt; Dict:\n    \"\"\"Get FASTQ dataset\n\n    Get FASTQ dataset by provided dataset_id or dataset_name\n    If dataset_name is not unique an error is printed\n\n    Args:\n        dataset_id: fq_dataset ID (or pk) to select\n        dataset_name: fq_dataset Name to select\n\n    Raises:\n        rsexceptions.ReadStoreError: If backend request failed\n        rsexceptions.ReadStoreError:\n            If multiple datasets found with same name.\n            This can occur if datasets with identical name were shared with you.\n\n    Returns:\n        Dict: Json Detail response\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n    if dataset_id is None and dataset_name is None: \n        raise rsexceptions.ReadStoreError(\"Dataset ID or Name Required\")\n\n    # Define json for post request\n    json = {}\n    if dataset_id:\n        json[\"id\"] = dataset_id\n    if dataset_name:\n        json[\"name\"] = dataset_name\n\n    res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n    # Remove entries not requested\n    if res.status_code not in [200, 204]:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"get_fastq_dataset failed: {detail}\")\n    else:\n        # If no dataset found, return empty dict\n        if len(res.json()) == 0:\n            return {}\n        # If several datasets found, return error\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Datasets Found.\\n\n                This can happen if datasets with identical name were\n                shared with you.\\nUse dataset_id to get the correct dataset.\"\"\"\n            )\n        else:\n            return res.json()[0]\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.get_fq_file","title":"<code>get_fq_file(fq_file_id)</code>","text":"<p>Get Fastq File</p> <p>Return Fastq file data by fq_file ID</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_id</code> <code>int</code> <p>ID (pk) of fq_file</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>dict with fq file data</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def get_fq_file(self, fq_file_id: int) -&gt; Dict:\n    \"\"\"Get Fastq File\n\n    Return Fastq file data by fq_file ID\n\n    Args:\n        fq_file_id: ID (pk) of fq_file\n\n    Returns:\n        dict with fq file data\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n    res = requests.get(fq_file_endpoint + f'{fq_file_id}/',auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"get_fq_file failed: {detail}\")\n    else:\n        return res.json()[0]\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.get_fq_file_upload_path","title":"<code>get_fq_file_upload_path(fq_file_id)</code>","text":"<p>Get FASTQ file upload path</p> <p>Get upload path for FASTQ file by fq_file ID</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_id</code> <code>int</code> <p>ID (pk) of FASTQ file</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If upload_path is not found</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Upload path</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def get_fq_file_upload_path(self, fq_file_id: int) -&gt; str:\n    \"\"\"Get FASTQ file upload path\n\n    Get upload path for FASTQ file by fq_file ID\n\n    Args:\n        fq_file_id: ID (pk) of FASTQ file\n\n    Raises:\n        rsexceptions.ReadStoreError: If upload_path is not found\n\n    Returns:\n        str: Upload path\n    \"\"\"\n\n    fq_file = self.get_fq_file(fq_file_id)\n\n    if \"upload_path\" not in fq_file:\n        raise rsexceptions.ReadStoreError(\"upload_path Not Found in FqFile entry\")\n\n    upload_path = fq_file.get(\"upload_path\")\n\n    return upload_path\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.get_output_format","title":"<code>get_output_format()</code>","text":"<p>Get Output Format set for client</p> Return <p>str output format</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def get_output_format(self) -&gt; str:\n    \"\"\"\n    Get Output Format set for client\n\n    Return:\n        str output format\n    \"\"\"\n\n    return self.output_format\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.get_pro_data","title":"<code>get_pro_data(pro_data_id=None, name=None, version=None, dataset_id=None, dataset_name=None)</code>","text":"<p>Get Processed Data</p> <p>Get Pro Data for Dataset</p> <p>Provide pro_data_id or name plus dataset_id or dataset_name to query</p> <p>Parameters:</p> Name Type Description Default <code>pro_data_id</code> <code>int | None</code> <p>Dataset ID</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Pro Data Name</p> <code>None</code> <code>version</code> <code>int | None</code> <p>Pro Data Version</p> <code>None</code> <code>dataset_id</code> <code>int | None</code> <p>Dataset ID</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Dataset Name</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Pro Data object</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def get_pro_data(self,\n                pro_data_id: int | None = None,\n                name: str | None = None,\n                version: int | None = None,\n                dataset_id: int | None = None,\n                dataset_name: str | None = None) -&gt; Dict:   \n    \"\"\"Get Processed Data\n\n    Get Pro Data for Dataset\n\n    Provide pro_data_id or name plus dataset_id or dataset_name to query\n\n    Args:\n        pro_data_id: Dataset ID\n        name: Pro Data Name\n        version: Pro Data Version\n        dataset_id: Dataset ID\n        dataset_name: Dataset Name\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n\n    Returns:\n        Dict: Pro Data object\n    \"\"\"\n\n    if not pro_data_id:\n        assert name and (dataset_id or dataset_name), \"name and dataset_id or dataset_name required\"\n\n    pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n    if not version:\n        valid = 'true'\n    else:\n        valid = 'false'\n\n    # Define json for post request\n    json = {\n        'dataset_id': dataset_id,\n        'dataset_name': dataset_name,\n        'name': name,\n        'version': version,\n        'valid': valid,\n        'detail': 'true'\n    }\n\n    if pro_data_id:\n        res = requests.get(pro_data_endpoint + f'{pro_data_id}/', auth=self.auth)\n    else:\n        res = requests.get(pro_data_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"list_pro_data failed {detail}\")\n    else:\n        if len(res.json()) == 0:\n            return {}\n        # If several datasets found, return error\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Projects Found.\\n\n            This can happen if Projects with identical name were shared with you.\\n\n            Use unique Project ID to access the correct dataset.\"\"\"\n            )\n        else:\n            return res.json()[0]\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.get_project","title":"<code>get_project(project_id=None, project_name=None)</code>","text":"<p>Get Individual Project</p> <p>Return project details by project_id or project_name If name is duplicated, print error message</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Project ID</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Project Name</p> <code>None</code> <p>Raise     rsexceptions.ReadStoreError: If request failed     rsexceptions.ReadStoreError: If duplicate names are found</p> <p>Returns:</p> Type Description <code>Dict</code> <p>project detail response</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def get_project(\n    self,\n    project_id: int | None = None,\n    project_name: str | None = None\n) -&gt; Dict:\n    \"\"\"Get Individual Project\n\n    Return project details by project_id or project_name\n    If name is duplicated, print error message\n\n    Args:\n        project_id: Project ID\n        project_name: Project Name\n\n    Raise\n        rsexceptions.ReadStoreError: If request failed\n        rsexceptions.ReadStoreError: If duplicate names are found\n\n    Returns:\n        project detail response\n    \"\"\"\n\n    assert project_id or project_name, \"project_id or project_name Required\"\n\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n    # Define json for post request\n    json = {\"username\": self.username, \"token\": self.token}\n\n    if project_id:\n        json[\"id\"] = project_id\n    if project_name:\n        json[\"name\"] = project_name\n\n    res = requests.get(project_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"get_project failed: {detail}\")\n    else:\n        if len(res.json()) == 0:\n            return {}\n        # If several datasets found, return error\n        elif len(res.json()) &gt; 1:\n            raise rsexceptions.ReadStoreError(\n                \"\"\"Multiple Projects Found.\\n\n            This can happen if Projects with identical name were shared with you.\\n\n            Use unique Project ID to access the correct dataset.\"\"\"\n            )\n        else:\n            return res.json()[0]\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.list_fastq_datasets","title":"<code>list_fastq_datasets(project_name=None, project_id=None, role=None)</code>","text":"<p>List FASTQ Datasets</p> <p>List FASTQ datasets and filter by project_name, project_id or role. Role can be owner, collaborator or creator.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str | None</code> <p>Filter fq_datasets by project name</p> <code>None</code> <code>project_id</code> <code>int | None</code> <p>Filter fq_datasets by project ID</p> <code>None</code> <code>role</code> <code>str | None</code> <p>Filter fq_datasets by owner role (owner, collaborator, creator)</p> <code>None</code> <p>Returns:</p> Type Description <code>List[dict]</code> <p>List[Dict]: FASTQ datasets in JSON format</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def list_fastq_datasets(\n    self,\n    project_name: str | None = None,\n    project_id: int | None = None,\n    role: str | None = None,\n) -&gt; List[dict]:\n    \"\"\"\n    List FASTQ Datasets\n\n    List FASTQ datasets and filter by project_name, project_id or role.\n    Role can be owner, collaborator or creator.\n\n    Args:\n        project_name: Filter fq_datasets by project name\n        project_id: Filter fq_datasets by project ID\n        role: Filter fq_datasets by owner role (owner, collaborator, creator)\n\n    Raises:\n        rsexceptions.ReadStoreError if role is not valid\n        rsexceptions.ReadStoreError request failed\n\n    Returns:\n        List[Dict]: FASTQ datasets in JSON format\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT)\n\n    # Define json for post request\n    json = {}\n\n    if role:\n        if role.lower() in [\"owner\", \"collaborator\", \"creator\"]:\n            json[\"role\"] = role\n        else:\n            raise rsexceptions.ReadStoreError(\"Invalid Role\")\n\n    if project_name:\n        json[\"project_name\"] = project_name\n    if project_id:\n        json[\"project_id\"] = project_id\n\n    res = requests.get(fq_dataset_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"list_fastq_datasets failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.list_fq_files","title":"<code>list_fq_files()</code>","text":"<p>List Fastq Files</p> <p>List Fastq files in ReadStore</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List of Fastq files</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def list_fq_files(self) -&gt; List[Dict]:\n    \"\"\"List Fastq Files\n\n    List Fastq files in ReadStore\n\n    Returns:\n        List of Fastq files\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT)\n\n    res = requests.get(fq_file_endpoint, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"list_fq_files failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.list_pro_data","title":"<code>list_pro_data(project_id=None, project_name=None, dataset_id=None, dataset_name=None, name=None, data_type=None, include_archived=False)</code>","text":"<p>List Processed Data</p> <p>List Pro Data. Subset by arguments.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int | None</code> <p>Project ID</p> <code>None</code> <code>project_name</code> <code>str | None</code> <p>Project Name</p> <code>None</code> <code>dataset_id</code> <code>int | None</code> <p>Dataset ID</p> <code>None</code> <code>dataset_name</code> <code>str | None</code> <p>Dataset Name</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Pro Data Name</p> <code>None</code> <code>data_type</code> <code>str | None</code> <p>Data Type</p> <code>None</code> <code>include_archived</code> <code>bool</code> <p>Include Archived Pro Data</p> <code>False</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: List of Pro Data</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def list_pro_data(self,\n                  project_id: int | None = None,\n                  project_name: str | None = None,\n                  dataset_id: int | None = None,\n                  dataset_name: str | None = None,\n                  name: str | None = None,\n                  data_type: str | None = None,\n                  include_archived: bool = False) -&gt; List[Dict]:\n    \"\"\"List Processed Data\n\n    List Pro Data. Subset by arguments.\n\n    Args:\n        project_id: Project ID\n        project_name: Project Name\n        dataset_id: Dataset ID\n        dataset_name: Dataset Name\n        name: Pro Data Name\n        data_type: Data Type\n        include_archived: Include Archived Pro Data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n\n    Returns:\n        List[Dict]: List of Pro Data\n    \"\"\"\n\n    pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n    # Define json for post request\n    json = {\n        'project_id': project_id,\n        'project_name': project_name,\n        'dataset_id': dataset_id,\n        'dataset_name': dataset_name,\n        'name': name,\n        'data_type': data_type\n    }\n\n    if not include_archived:\n        json['valid'] = True\n\n    res = requests.get(pro_data_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"list_pro_data failed {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.list_projects","title":"<code>list_projects(role=None)</code>","text":"<p>List Projects</p> <p>List projects and optionally filter by role</p> <p>Parameters:</p> Name Type Description Default <code>role</code> <code>str | None</code> <p>Owner role to filter (owner, collaborator, creator)</p> <code>None</code> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If role is not valid</p> <code>ReadStoreError</code> <p>If request failed</p> <p>Returns:</p> Type Description <code>List[Dict]</code> <p>List[Dict]: List of projects</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def list_projects(self, role: str | None = None) -&gt; List[Dict]:\n    \"\"\"List Projects\n\n    List projects and optionally filter by role\n\n    Args:\n        role: Owner role to filter (owner, collaborator, creator)\n\n    Raises:\n        rsexceptions.ReadStoreError: If role is not valid\n        rsexceptions.ReadStoreError: If request failed\n\n    Returns:\n        List[Dict]: List of projects\n    \"\"\"\n\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT)\n\n    # Define json for post request\n    json = {}\n    if role:\n        if role.lower() in [\"owner\", \"collaborator\", \"creator\"]:\n            json[\"role\"] = role\n        else:\n            raise rsexceptions.ReadStoreError(\"Invalid Role\")\n\n    res = requests.get(project_endpoint, params=json, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"list_projects failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.update_fastq_dataset","title":"<code>update_fastq_dataset(dataset_id, name, description, qc_passed, paired_end, index_read, project_ids, project_names, metadata, fq_file_r1_id, fq_file_r2_id, fq_file_i1_id, fq_file_i2_id)</code>","text":"<p>Update Fastq Dataset</p> <p>Update Fastq dataset in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>int</code> <p>ID of the dataset to update</p> required <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>qc_passed</code> <code>bool</code> <p>QC Pass</p> required <code>paired_end</code> <code>bool</code> <p>Paired End</p> required <code>index_read</code> <code>bool</code> <p>Index Read</p> required <code>project_ids</code> <code>List[int]</code> <p>List of project IDs</p> required <code>project_names</code> <code>List[str]</code> <p>List of project names</p> required <code>metadata</code> <code>dict</code> <p>Metadata</p> required <code>fq_file_r1_id</code> <code>int | None</code> <p>Fastq file R1 ID</p> required <code>fq_file_r2_id</code> <code>int | None</code> <p>Fastq file R2 ID</p> required <code>fq_file_i1_id</code> <code>int | None</code> <p>Fastq file I1 ID</p> required <code>fq_file_i2_id</code> <code>int | None</code> <p>Fastq file I2 ID</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Updated Fastq dataset</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def update_fastq_dataset(self,\n                         dataset_id: int,\n                         name: str,\n                         description: str,\n                         qc_passed: bool,\n                         paired_end: bool,\n                         index_read: bool,\n                         project_ids: List[int],\n                         project_names: List[str],\n                         metadata: dict,\n                         fq_file_r1_id: int | None,\n                         fq_file_r2_id: int | None,\n                         fq_file_i1_id: int | None,\n                         fq_file_i2_id: int | None) -&gt; dict:\n    \"\"\"Update Fastq Dataset\n\n    Update Fastq dataset in ReadStore\n\n    Args:\n        dataset_id: ID of the dataset to update\n        name: Dataset name\n        description: Dataset description\n        qc_passed: QC Pass\n        paired_end: Paired End\n        index_read: Index Read\n        project_ids: List of project IDs\n        project_names: List of project names\n        metadata: Metadata\n        fq_file_r1_id: Fastq file R1 ID\n        fq_file_r2_id: Fastq file R2 ID\n        fq_file_i1_id: Fastq file I1 ID\n        fq_file_i2_id: Fastq file I2 ID\n\n    Returns:\n        dict: Updated Fastq dataset\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_dataset_endpoint = os.path.join(self.endpoint, self.FQ_DATASET_ENDPOINT, f'{dataset_id}/')\n\n    # Define json for put request\n    json = {\n        \"name\": name,\n        \"description\": description,\n        \"qc_passed\": qc_passed,\n        \"paired_end\": paired_end,\n        \"index_read\": index_read,\n        \"project_ids\": project_ids,\n        \"project_names\": project_names,\n        \"metadata\": metadata,\n        \"fq_file_r1\": fq_file_r1_id,\n        \"fq_file_r2\": fq_file_r2_id,\n        \"fq_file_i1\": fq_file_i1_id,\n        \"fq_file_i2\": fq_file_i2_id\n    }\n\n    res = requests.put(fq_dataset_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 200:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"update_fastq_dataset failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.update_fq_file","title":"<code>update_fq_file(fq_file_id, name, read_type, qc_passed, read_length, num_reads, size_mb, qc_phred_mean, qc_phred, upload_path, md5_checksum, staging, pipeline_version)</code>","text":"<p>Update Fastq File</p> <p>Update Fastq file in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>fq_file_id</code> <code>int</code> <p>ID of Fastq file</p> required <code>name</code> <code>str</code> <p>Fastq file name</p> required <code>read_type</code> <code>str</code> <p>Read type (R1, R2, I1, I2)</p> required <code>qc_passed</code> <code>bool</code> <p>QC Pass</p> required <code>read_length</code> <code>int</code> <p>Read length</p> required <code>num_reads</code> <code>int</code> <p>Number of reads</p> required <code>size_mb</code> <code>int</code> <p>Size in MB</p> required <code>qc_phred_mean</code> <code>float</code> <p>QC Phred Mean</p> required <code>qc_phred</code> <code>dict</code> <p>QC Phred</p> required <code>upload_path</code> <code>str</code> <p>Upload Path</p> required <code>md5_checksum</code> <code>str</code> <p>MD5 Checksum</p> required <code>staging</code> <code>bool</code> <p>Staging</p> required <code>pipeline_version</code> <code>str</code> <p>Pipeline Version</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Fastq file data</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def update_fq_file(self,\n                   fq_file_id: int,\n                   name: str,\n                   read_type: str,\n                   qc_passed: bool,\n                   read_length: int,\n                   num_reads: int,\n                   size_mb: int,\n                   qc_phred_mean: float,\n                   qc_phred: dict,\n                   upload_path: str,\n                   md5_checksum: str,\n                   staging: bool,\n                   pipeline_version: str) -&gt; dict:\n\n    \"\"\"Update Fastq File\n\n    Update Fastq file in ReadStore\n\n    Args:\n        fq_file_id: ID of Fastq file\n        name: Fastq file name\n        read_type: Read type (R1, R2, I1, I2)\n        qc_passed: QC Pass\n        read_length: Read length\n        num_reads: Number of reads\n        size_mb: Size in MB\n        qc_phred_mean: QC Phred Mean\n        qc_phred: QC Phred\n        upload_path: Upload Path\n        md5_checksum: MD5 Checksum\n        staging: Staging\n        pipeline_version: Pipeline Version\n\n    Returns:    \n        dict: Fastq file data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n\n    fq_file_endpoint = os.path.join(self.endpoint, self.FQ_FILE_ENDPOINT, f'{fq_file_id}/')\n\n    # Define json for post request\n    json = {\n        \"name\": name,\n        \"read_type\": read_type,\n        \"qc_passed\": qc_passed,\n        \"read_length\": read_length,\n        \"num_reads\": num_reads,\n        \"size_mb\": size_mb,\n        \"qc_phred_mean\": qc_phred_mean,\n        \"qc_phred\": qc_phred,\n        \"upload_path\": upload_path,\n        \"md5_checksum\": md5_checksum,\n        \"staging\": staging,\n        \"pipeline_version\": pipeline_version\n    }\n\n    res = requests.put(fq_file_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 200:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"update_fq_file failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.update_project","title":"<code>update_project(project_id, name, description, metadata, dataset_metadata_keys)</code>","text":"<p>Update Project</p> <p>Update an existing project in ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>int</code> <p>ID of the project to update</p> required <code>name</code> <code>str</code> <p>Project name</p> required <code>description</code> <code>str</code> <p>Project description</p> required <code>metadata</code> <code>dict</code> <p>Project metadata</p> required <code>dataset_metadata_keys</code> <code>List[str]</code> <p>Dataset metadata keys</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Updated project data</p> <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def update_project(self,\n                   project_id: int,\n                   name: str,\n                   description: str,\n                   metadata: dict,\n                   dataset_metadata_keys: List[str]) -&gt; dict:        \n    \"\"\"Update Project\n\n    Update an existing project in ReadStore\n\n    Args:\n        project_id: ID of the project to update\n        name: Project name\n        description: Project description\n        metadata: Project metadata\n        dataset_metadata_keys: Dataset metadata keys\n\n    Returns:\n        dict: Updated project data\n\n    Raises:\n        rsexceptions.ReadStoreError: If request failed\n    \"\"\"\n    project_endpoint = os.path.join(self.endpoint, self.PROJECT_ENDPOINT, f'{project_id}/')\n\n    dataset_metadata_keys = {key: \"\" for key in dataset_metadata_keys}\n\n    json = {\n        \"name\": name,\n        \"description\": description,\n        \"metadata\": metadata,\n        \"dataset_metadata_keys\": dataset_metadata_keys\n    }\n\n    res = requests.put(project_endpoint, json=json, auth=self.auth)\n\n    if res.status_code != 200:\n\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"update_project failed: {detail}\")\n    else:\n        return res.json()\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.upload_fastq","title":"<code>upload_fastq(fastq_path, fastq_name=None, read_type=None)</code>","text":"<p>Upload Fastq Files</p> <p>Upload Fastq files to ReadStore. Check if file exists and has read permissions.</p> <p>fastq_name: List of Fastq names for files to upload read_type: List of read types for files to upload</p> <p>Parameters:</p> Name Type Description Default <code>fastq_path</code> <code>str</code> <p>List of Fastq files to upload</p> required <code>fastq_name</code> <code>str | None</code> <p>List of Fastq names for files to upload</p> <code>None</code> <code>read_types</code> <p>List of read types for files to upload</p> required <code>read_types</code> <p>Must be in ['R1', 'R2', 'I1', 'I2']</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If file not found</p> <code>ReadStoreError</code> <p>If no read permissions</p> <code>ReadStoreError</code> <p>If upload URL request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def upload_fastq(self,\n                 fastq_path: str,\n                 fastq_name: str | None = None,\n                 read_type: str | None = None) -&gt; None:\n    \"\"\"Upload Fastq Files\n\n    Upload Fastq files to ReadStore.\n    Check if file exists and has read permissions.\n\n    fastq_name: List of Fastq names for files to upload\n    read_type: List of read types for files to upload\n\n    Args:\n        fastq_path: List of Fastq files to upload\n        fastq_name: List of Fastq names for files to upload\n        read_types: List of read types for files to upload\n        read_types: Must be in ['R1', 'R2', 'I1', 'I2']\n\n    Raises:\n        rsexceptions.ReadStoreError: If file not found\n        rsexceptions.ReadStoreError: If no read permissions\n        rsexceptions.ReadStoreError: If upload URL request failed\n    \"\"\"\n\n    fq_upload_endpoint = os.path.join(self.endpoint, self.FASTQ_UPLOAD_ENDPOINT)\n\n    # Run parallel uploads of fastq files\n    fastq_path = os.path.abspath(fastq_path)\n\n    # Make sure file exists and\n    if not os.path.exists(fastq_path):\n        raise rsexceptions.ReadStoreError(f\"File Not Found: {fastq_path}\")\n    elif not os.access(fastq_path, os.R_OK):\n        raise rsexceptions.ReadStoreError(f\"No read permissions: {fastq_path}\")\n\n    payload = {\n        \"fq_file_path\": fastq_path,\n    }\n\n    if not fastq_name is None:\n        if fastq_name == \"\":\n            raise rsexceptions.ReadStoreError(\"Fastq Name Is Empty\")\n        if not self.validate_charset(fastq_name):\n            raise rsexceptions.ReadStoreError(\"Invalid Fastq Name\")\n        payload[\"fq_file_name\"] = fastq_name\n\n    if not read_type is None:\n        if read_type not in [\"R1\", \"R2\", \"I1\", \"I2\"]:\n            raise rsexceptions.ReadStoreError(\"Invalid Read Type\")\n        payload[\"read_type\"] = read_type\n\n    res = requests.post(fq_upload_endpoint, json=payload, auth=self.auth)\n\n    if res.status_code not in [200, 204]:\n        res_message = res.json().get(\"detail\", \"No Message\")\n        raise rsexceptions.ReadStoreError(\n            f\"Upload URL Request Failed: {res_message}\"\n        )\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.upload_pro_data","title":"<code>upload_pro_data(name, pro_data_path, data_type, dataset_id=None, dataset_name=None, metadata={}, description='')</code>","text":"<p>Upload Processed Data</p> <p>Upload Pro Data to ReadStore</p> <p>Parameters:</p> Name Type Description Default <code>pro_data</code> <p>Pro Data in JSON format</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If upload request failed</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def upload_pro_data(self,\n                    name: str,\n                    pro_data_path: str,\n                    data_type: str,\n                    dataset_id: int | None = None,\n                    dataset_name: str | None = None,\n                    metadata: dict = {},\n                    description: str = \"\") -&gt; None:\n    \"\"\"Upload Processed Data\n\n    Upload Pro Data to ReadStore\n\n    Args:\n        pro_data: Pro Data in JSON format\n\n    Raises:\n        rsexceptions.ReadStoreError: If upload request failed\n    \"\"\"\n\n    pro_data_endpoint = os.path.join(self.endpoint, self.PRO_DATA_ENDPOINT)\n\n    if name == '':\n        raise rsexceptions.ReadStoreError(\"Empty Name\")\n    if data_type == '':\n        raise rsexceptions.ReadStoreError(\"Empty Data Type\")\n    if not self.validate_charset(name):\n        raise rsexceptions.ReadStoreError(\"Invalid character in name. Must be alphanumeric or _-.@\")\n    if not self.validate_charset(data_type):\n        raise rsexceptions.ReadStoreError(\"Invalid character in data_type. Must be alphanumeric or _-.@\")\n\n    self.validate_metadata(metadata)\n\n    # Run parallel uploads of fastq files\n    pro_data_path = os.path.abspath(pro_data_path)\n\n    # Make sure file exists and\n    if not os.path.exists(pro_data_path):\n        raise rsexceptions.ReadStoreError(f\"File Not Found: {pro_data_path}\")\n    elif not os.access(pro_data_path, os.R_OK):\n        raise rsexceptions.ReadStoreError(f\"No read permissions: {pro_data_path}\")\n\n    # Define json for post request\n    json = {\n        \"name\" : name,\n        \"data_type\": data_type,\n        \"upload_path\": pro_data_path,\n        \"metadata\": metadata,\n        \"description\" : description,\n    }\n\n    if dataset_id:\n        json['dataset_id'] = dataset_id\n    if dataset_name:\n        json['dataset_name'] = dataset_name        \n\n    res = requests.post(pro_data_endpoint, json=json, auth=self.auth)\n\n    if res.status_code == 403:\n        raise rsexceptions.ReadStoreError(f\"Upload ProData Failed: {res.json().get('detail')}\")\n    elif res.status_code not in [201, 204]:\n        try:\n            detail = res.json()\n        except JSONDecodeError:\n            detail = \"No Message\"\n\n        raise rsexceptions.ReadStoreError(f\"upload_pro_data failed: {detail}\")\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.validate_charset","title":"<code>validate_charset(query_str)</code>","text":"<p>Validate charset for query string</p> <p>Parameters:</p> Name Type Description Default <code>query_str</code> <code>str</code> <p>Query string to validate</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def validate_charset(self, query_str: str) -&gt; bool:\n    \"\"\"\n    Validate charset for query string\n\n    Args:\n        query_str (str): Query string to validate\n\n    Returns:\n        bool: \n    \"\"\"\n\n    allowed = string.digits + string.ascii_lowercase + string.ascii_uppercase + '_-.@'\n    allowed = set(allowed)\n\n    return set(query_str) &lt;= allowed\n</code></pre>"},{"location":"reference/readstore/#pyreadstore.rsclient.RSClient.validate_metadata","title":"<code>validate_metadata(metadata)</code>","text":"<p>Validate metadata dict</p> <p>Ensure keys are non-empty, valid charset and not reserved</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>Metadata to validate</p> required <p>Raises:</p> Type Description <code>ReadStoreError</code> <p>If key is invalid</p> Source code in <code>pyreadstore/rsclient.py</code> <pre><code>def validate_metadata(self, metadata: dict) -&gt; None:\n    \"\"\"\n    Validate metadata dict\n\n    Ensure keys are non-empty, valid charset and not reserved\n\n    Args:\n        metadata (dict): Metadata to validate\n\n    Raises:\n        rsexceptions.ReadStoreError: If key is invalid\n    \"\"\"\n\n    for key, value in metadata.items():\n        if key == '':\n            raise rsexceptions.ReadStoreError(\"Empty Key\")\n        if not self.validate_charset(key):\n            raise rsexceptions.ReadStoreError(\"Invalid character in key. Must be alphanumeric or _-.@\")\n        if key in self.METADATA_RESERVED_KEYS:\n            raise rsexceptions.ReadStoreError(f\"Reserved Keyword not allowed in metadata: {key}\")\n</code></pre>"},{"location":"reference/readstore/#rsdataclasses-module","title":"rsdataclasses module","text":"<p>Provides Pydantic data classes for ReadStore API validation.</p>"},{"location":"reference/readstore/#rsexceptions-module","title":"rsexceptions module","text":""},{"location":"reference/readstore/#pyreadstore.rsexceptions.ReadStoreError","title":"<code>ReadStoreError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for ReadStoreError exceptions.</p> Source code in <code>pyreadstore/rsexceptions.py</code> <pre><code>class ReadStoreError(Exception):\n    \"\"\"Base class for ReadStoreError exceptions.\"\"\"\n    def __init__(self, message: str):\n        super().__init__(message)\n        self.message = message\n</code></pre>"}]}